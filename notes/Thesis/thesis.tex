\documentclass[a4paper, 12pt, twoside]{report}
\usepackage[english]{babel}
\usepackage[top=4cm,bottom=4cm,left=3cm,right=3cm,asymmetric]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsfonts, amsthm, dsfont}
\usepackage{relsize}
\usepackage{tikz}
\usetikzlibrary{arrows, arrows.meta, calc, positioning}
\usepackage{float}
\usepackage{caption}
\usepackage{fancyhdr}
\usepackage{bibgerm} 
\usepackage{cite}
\usepackage[hidelinks]{hyperref}
\usepackage[all]{hypcap}
\usepackage{subcaption} 
\usepackage{setspace}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{blindtext}
\usepackage{listings}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\captionsetup[figure]{labelfont=it, font=footnotesize}
\captionsetup[subfigure]{labelfont=it,font=footnotesize}

%\theoremstyle{plain}
%\newtheorem{theorem}{Theorem}[chapter]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}

%\theoremstyle{definition}
%\newtheorem{def_sally}[theorem]{Definition}
%\colorlet{shadecolor}{gray!10}
%\newenvironment{definition}
%{\begin{shaded}\begin{def_sally}}
%		{\end{def_sally}\end{shaded}}
	
	
	
%Definition
\newcounter{defcounter}[section] \setcounter{defcounter}{0}
\renewcommand{\thedefcounter}{\arabic{section}.\arabic{defcounter}}
\newenvironment{definition}[2][]{%
	\refstepcounter{defcounter}%
	\ifstrempty{#1}%
	{\mdfsetup{%
			frametitle={%
				\tikz[baseline=(current bounding box.east),outer sep=0pt]
				\node[anchor=east,rectangle,fill=white]
				{\strut Definition~\thedefcounter};}}
	}%
	{\mdfsetup{%
			frametitle={%
				\tikz[baseline=(current bounding box.east),outer sep=0pt]
				\node[anchor=east,rectangle,fill=white]
				{\strut Definition~\thedefcounter:~#1};}}%
	}%
	\mdfsetup{innertopmargin=10pt,%
		linewidth=1pt,topline=true,, %
		frametitleaboveskip=\dimexpr-\ht\strutbox\relax
	}
	\begin{mdframed}[]\relax%
		\label{#2}}{\end{mdframed}}	
	
%Theorem	
%\newcounter{thmcounter}[section] \setcounter{thmcounter}{0}
%\renewcommand{\thethmcounter}{\arabic{section}.\arabic{thmcounter}}
\newenvironment{theorem}[2][]{%
	\refstepcounter{defcounter}%
	\ifstrempty{#1}%
	{\mdfsetup{%
			frametitle={%
				\tikz[baseline=(current bounding box.east),outer sep=0pt]
				\node[anchor=east,rectangle,fill=white]
				{\strut Theorem~\thedefcounter};}}
	}%
	{\mdfsetup{%
			frametitle={%
				\tikz[baseline=(current bounding box.east),outer sep=0pt]
				\node[anchor=east,rectangle,fill=white]
				{\strut Theorem~\thedefcounter:~#1};}}%
	}%
	\mdfsetup{innertopmargin=10pt,%
		linewidth=1pt,topline=true,, %
		frametitleaboveskip=\dimexpr-\ht\strutbox\relax
	}
	\begin{mdframed}[]\relax%
		\label{#2}}{\end{mdframed}}		

\newcommand*\ruleline[1]{\par\noindent\raisebox{.8ex}{\makebox[\linewidth]{\hrulefill\hspace{1ex}\raisebox{-.8ex}{#1}\hspace{1ex}\hrulefill}}}


\parindent0em

\begin{document}
	
	\begin{titlepage}
		\centering
		{\large \scshape Rheinisch-Westfälische Technische Hochschule Aachen}\\
		{\large
			Chair for Software Modeling and Verification\\
			Prof. Dr. Ir. Dr. h. c. Joost-Pieter Katoen\\}
		\vspace*{\fill}
		{\large \ruleline{Master Thesis}}\\
		\vspace{1cm}
		\textbf{\Huge Comparing Hierarchical and On-The-Fly Model Checking for Java Pointer Programs}\\
		\vspace{1cm}
		\hrule
		\vspace{1cm}
		{\Large \textbf{Sally Chau} \\}
		\vspace{0.25cm}
		{\large Matriculation Number 370584} \\
		%\vspace{0.3cm}
		{\large \today}\\
		\vspace{3cm}
		{\large First Reviewer: apl. Prof. Dr. Thomas Noll \\ Second Reviewer: Prof. Dr. Ir. Dr. h. c. Joost-Pieter Katoen \\ Supervisor: Christoph Matheja} \\ 
		\vspace{1cm}
		\vspace*{\fill}
	\end{titlepage}
	
	\pagestyle{empty}
	
	\clearpage\mbox{}\clearpage
	
	\chapter*{Acknowledgement} 
	
	
	\clearpage\mbox{}\clearpage
	
	\chapter*{Eidesstattliche Erklärung}
	
	Hiermit versichere ich an Eides statt und durch meine Unterschrift, dass die vorliegende Arbeit von mir selbstständig, ohne fremde Hilfe angefertigt worden ist. Inhalte und Passagen, die aus fremden Quellen stammen und direkt oder indirekt übernommen worden sind, wurden als solche kenntlich gemacht. Ferner versichere ich, dass ich keine andere, außer der im Literaturverzeichnis angegebenen Literatur verwendet habe. Die Arbeit wurde bisher keiner Prüfungsbehörde vorgelegt und auch noch nicht veröffentlicht.
	\vspace{20 mm}
	
	\noindent\line(1,0){250}\\
	Aachen, den 19. Juli 2019, Sally Chau
	
	\clearpage\mbox{}\clearpage
	
	\chapter*{Abstract}
	
	\clearpage\mbox{}\clearpage
	
	\doublespacing
	\tableofcontents
	\singlespacing
	\clearpage\mbox{}\clearpage
	\thispagestyle{empty} 
	
	\pagestyle{fancy}
	\fancyhead[RE]{\nouppercase\leftmark}
	\fancyhead[LO]{\nouppercase\rightmark}
	\fancyhead[LE,RO]{\thepage}
	\cfoot{}
	
	
	\chapter{Introduction}
	- introduce current status of model checking in attestor: after state space generation, only checking top level state space\\
	- goal: model check procedure state spaces \\
	- present possible algorithms: automata-based and on-the-fly tableau\\
	- always keep goal of hierarchical model checking in mind
	
	
	\section{\textsc{Attestor}}\label{sec:attestor}
	
	\textsc{Attestor} is a verification tool that generates an abstract state space of the input program and employs LTL model checking to verify specified properties. The state space generation is based on a finite representation of the program heap during execution by a (hyper)graph. Finiteness is achieved by employing abstraction based on graph grammars that specify the data structured maintained by the program and how subgraphs can be summarized in a so called hyperedges. Occurring methods in the input program are summarized by procedure contracts that specify the heap configurations prior to and after their execution. Thus, procedure state spaces do not need to be computed repeatedly for the same heap configuration. In a next step, property verification is performed by model checking the resulting state space against the LTL specifications. \textsc{Attestor} then either outputs that the program fulfills or (possibly) violates the property. In the latter case, a counterexample is provided.\\
	
	The structure of \textsc{Attestor} can be mainly divided into five parts, namely input, back-end, front-end, API and output, which is depicted in Figure~\ref{fig:attestor}. In order to specify a verification task, \textsc{Attestor} offers four possible input parameters of which the input program is mandatory. The user can further specify LTL specifications to be verified during model checking, a graph grammar for the data structures present in the input program, and further options such as initial heap configurations or properties to modify abstraction or garbage collection. The core of the \textsc{Attestor} tool is the back-end which describes the verification process. The \textsc{Attestor} front-end communicates via the \textsc{Attestor} API with the back-end to visualize the output such as the generated state space.\\	
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{\textwidth}{!}{
			\begin{tikzpicture}
			%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
			[node distance=2cm,thick,
			normal/.style={circle, draw, fill=white, thick},
			rectstyle/.style={draw, minimum width=8cm, minimum height=10cm, rounded corners=1.5pt, fill=gray!10},
			phase/.style={draw, minimum width=7.5cm, minimum height=1cm, rounded corners=1.5pt, fill=white},
			input/.style={draw, minimum width=4cm, minimum height=1cm, rounded corners=1.5pt, fill=white}]
			
			\node (back) at (0,0.25) [rectstyle] {};
			\node (backlabel) at (-2,5.5) {\textsc{Attestor} \textbf{Back-End}};
			
			\node (a1) at (0,4) [phase] {Parsing Inputs};
			\node (a2) at (0,2.5) [phase] {Marking Generation};
			\node (a3) at (0,1) [phase] {Grammar \& Abstraction Preprocessing};
			\node (a4) at (0,-0.5) [phase] {State Space Generation};
			\node (a5) at (0,-2) [phase] {Model Checking};
			\node (a6) at (0,-3.5) [phase] {Counterexample Generation};
			
			\node (i1) at (-7,4) [input] {Program};
			\node (i2) at (-7,2) [input] {LTL Specification};
			\node (i3) at (-7,0) [input] {Graph Grammar};
			\node (i4) at (-7,-2) [input] {Options};
			
			\node (o1) at (7,4) [input] {Abstract State Space};
			\node (o2) at (7,2) [input] {Procedure Contracts};
			
			\node (v1) at (7,-0.5) [input, fill=green!20] {Yes};
			\node (v2) at (7,-2) [input, fill=red!20] {No};
			\node (v3) at (7,-3.5) [input, fill=gray!20] {Don't Know};
			
			\draw[->,shorten >=0.5pt] (i1) to (-4,4);
			\draw[->,shorten >=0.5pt] (i2) to (-4,2);
			\draw[->,shorten >=0.5pt] (i3) to (-4,0);
			\draw[->,shorten >=0.5pt] (i4) to (-4,-2);
			
			\draw[->,shorten >=0.5pt] (4,4) to (o1);
			\draw[->,shorten >=0.5pt] (4,2) to (o2);
			
			\draw[->,shorten >=0.5pt] (0,5) to (a1);
			\draw[->,shorten >=0.5pt] (a1) to (a2);
			\draw[->,shorten >=0.5pt] (a2) to (a3);
			\draw[->,shorten >=0.5pt] (a3) to (a4);
			\draw[->,shorten >=0.5pt] (a4) to (a5);
			\draw[->,shorten >=0.5pt] (a5) to (a6);
			
			\path[] (4,-0.25) edge (4.5,-0.25);
			\path[] (4.5,-0.25) edge (4.5,-3.75);
			\path[] (4.5,-3.75) edge (4,-3.75);
			\draw[->,shorten >=0.5pt] (4.5,-0.5) to (v1);
			\draw[->,shorten >=0.5pt] (4.5,-2) to (v2);
			\draw[->,shorten >=0.5pt] (4.5,-3.5) to (v3);
			
			\draw[line width=3pt] (-9, -5.5) to (9,-5.5);
			\node (api) at (7.5,-5.25) {\textsc{Attestor} \textbf{API}};
			
			
			\node (front) at (0,-7) [draw, minimum width=18cm, minimum height=2cm, rounded corners=1.5pt, fill=gray!10] {\textsc{Attestor} \textbf{Front-End}};
			
			\end{tikzpicture}}
			\caption{\textsc{Attestor} architecture. \cite{arndt2018let}}\label{fig:attestor}
		\end{center}
	\end{figure}
	
	The \textsc{Attestor} back-end constitutes the core process of the tool which is divided into six phases. The first three phases comprise the preprocessing of the verification task, followed by the state space generation phase and the model checking phase.
	
	\paragraph{Phase 1: Parsing Inputs}
	In the first phase, the supplied input options passed to \textsc{Attestor} are read including the input program, graph grammars, initial heap configurations as well as procedure contracts that contain predefined pre- and post-conditions that describe the behavior of a procedure execution.
	
	\paragraph{Phase 2: Marking Generation} 
	After parsing the input, markings are added to the initial heap if required by the specified LTL properties \cite{heinen2015verifyingPhd}. The markings track object identities during program execution along sequences of states so that properties such as neighborhood preservation can be checked.\\
	
	\paragraph{Phase 3: Grammar and Abstraction Preprocessing}
	In this phase, state space generation is prepared by refining the input grammar such that properties can be decided more efficiently, e.g., by only considering hypergraphs that satisfy a specified property. Furthermore, abstraction preprocessing computes the transformers required for state space generation itself, e.g., garbage collection. 
	
	\paragraph{Phase 4: State Space Generation}	
	After the stages of preprocessing, the state space is generated by executing the statements of the input program on the initial heap such that new states are added. The procedure is illustrated in Figure~\ref{fig:stateSpaceGeneration}. The abstract execution loop is executed until either there are no more states left to process or a fixpoint has been reached. The loop starts with picking a state, which has not been processed yet, at random. The abstract semantics of the next statement are applied to the state. Therefore, the heap configuration potentially needs to be locally concretised so that the statement is executed on a concrete heap configuration. Concretisation is achieved by applying the grammar rules in a forward manner. Thereafter, the heap is cleared, e.g., dead variables are removed and the garbage collector performs its actions. In order to obtain a compact heap representation, an abstraction of the heap is followed where grammar rules are applied in a backward manner. Therefore, embeddings of the heap configuration in the right hand side of grammar rules have to be found. Finally, the resulting state is labeled with atomic propositions that are satisfied by the heap configuration. The labeling is implemented by heap automata \cite{arndt2018let}. Before adding the resulting state to the state space, it is checked whether a  more abstract state already covers the current state. If not, the state is added to the state space and the algorithm continues with the next state. Else, \textsc{Attestor} checks whether a fixpoint has been reached and terminates the procedure in this case. Otherwise, state space generation continues. The generated state space represents the transformation of the initial heap configuration during program execution for the main method of the input program.
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{\textwidth}{!}{
			\begin{tikzpicture}
			[node distance=2cm,thick,
			normal/.style={circle, draw, fill=white, thick},
			rectstyle/.style={draw, minimum width=8cm, minimum height=9cm, rounded corners=1.5pt, fill=gray!10},
			phase/.style={draw, minimum width=5cm, minimum height=1cm, rounded corners=1.5pt, fill=white}]
			
			\node (init) at (0,7.5) [phase] {add initial states};
			\node (pick) at (0,6) [phase] {pick state in state space};
			
			\node (back) at (0,0) [rectstyle] {};
			\node (exec) at (-2.1, 4.75) [] {\textbf{abstract execution}};
			
			\node (abstract) at (-2.6,-3) [draw, minimum width=10.75cm, minimum height=10.5cm, rounded corners=1.5pt, fill=orange, fill opacity=0.2] {};
			\node at (0, 1.9) {\textit{for each resulting state}};
			
			\node (p1) at (0,3.5) [phase] {concretise};
			\node (p2) at (0,1) [phase] {execute statement};
			\node (p3) at (0,-0.5) [phase] {rectify};
			\node (p4) at (0,-2) [phase] {abstract};
			\node (p5) at (0,-3.5) [phase] {label};
			
			\node (d1) at (0, -6.5) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
			\node (d1text) at (d1) [align=center] {subsumed\\ by existing\\ state};
			
			\node (d2) at (6, -6.5) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
			\node (d2text) at (d2) [align=center] {fixpoint\\ reached};
			
			\node (add) at (-6,-6.5) [draw, minimum width=3cm, minimum height=1cm, rounded corners=1.5pt, fill=white] {add to state space};
			
			\draw[->,shorten >=0.5pt] (0,8.5) to (init);
			\draw[->,shorten >=0.5pt] (init) to (pick);
			\draw[->,shorten >=0.5pt] (pick) to (p1);
			\draw[->,shorten >=0.5pt] (p1) to (0,2.25);
			\draw[->,shorten >=0.5pt] (p2) to (p3);
			\draw[->,shorten >=0.5pt] (p3) to (p4);
			\draw[->,shorten >=0.5pt] (p4) to (p5);			
			\draw[->,shorten >=0.5pt] (p5) to (0,-4.9);
			
			\draw[->,shorten >=0.5pt] (-1.5,-6.5) -- node[above] {\texttt{no}} (add);
			\draw[->,shorten >=0.5pt] (1.5,-6.5) -- node[above] {\texttt{yes}} (4.5,-6.5);
			
			\path (add) edge (-6,6);
			\draw[->,shorten >=0.5pt] (-6,6) to (pick);
			
			\path (6,-4.9) edge node[right] {\texttt{no}} (6,6);
			\draw[->,shorten >=0.5pt] (6,6) to (pick);
			
			\draw[->,shorten >=0.5pt] (7.5,-6.5) -- node[above] {\texttt{yes}} (8.5,-6.5);
			
			\end{tikzpicture}}
			\caption{Phase 4: State space generation in \textsc{Attestor} \cite{arndt2018let}.}\label{fig:stateSpaceGeneration}
		\end{center}
	\end{figure}
	
	\paragraph{Phase 5: Model Checking}
	State space generation is followed by the model checking phase if LTL formulae have been specified. \textsc{Attestor} currently implements the tableaux method described in Section \ref{sec:tableaux} which checks the main state space for LTL formulae. In case a formulae is violated, a failure trace is returned that constitutes a counterexample generated in the next phase. If all properties are satisfied, \textsc{Attestor} outputs accordingly. A drawback of the current model checking procedure is that procedural programs contain (recursive) methods and method calls with proper state spaces that are not (directly) checked in the current implementation. Rather, procedure calls are woven into the main state space by considering their influence on the heap configuration only after the execution. However, properties should also be checked for the procedure state spaces themselves as they might introduce violations not visible in the main state space. We approach this gap by considering hierarchical model checking in Chapters ~\ref{chp:hmc} and ~\ref{chp:otf} that also verifies procedure state spaces for the specified LTL properties.
	
	\paragraph{Phase 6: Counterexample Generation}
	In case an LTL formula is found to be violated, the model checking phase returns a failure trace. Together with the violated formula a counterexample is generated in this phase in order to provide an instance for debugging purposes.

	\section{Related Work}
	
	\chapter{Preliminaries}
	
	Model checking is a formal verification technique that systematically analyses whether the system under consideration satisfies a set of specified properties. It then either returns that the system fulfills the desired properties or outputs a counterexample if a property is violated. The resulting counterexample offers useful information for debugging purposes. Two parameters are crucial for model checking in order to obtain an expressive and valuable outcome: the \textit{model} of the system under consideration and the formal description of the \textit{properties} the model is to be checked for.  
	
	\section{System Model}
	
	An important aspect in model checking is the model of the system under consideration. A model describes the behavior of the system. The more accurate the model represents the system, the more expressive the model checking results are. In this section, we first introduce the general concept of \textit{transition systems} that are commonly used to represent hardware and software systems. In order to describe \textit{hierarchical} system structures relevant to modeling pointer-manipulating programs, we focus on \textit{recursive state machines} that capture the hierarchical (or recursive) nature of method calls in programs. \\
	
	The states of the transition system consist of heap configurations that accommodate information about the current state of the program execution. As the heap can become unboundedly large, we introduce \textit{hypergraphs} and \textit{graph grammars}, that offer a finite representation for heap configurations, in the second part of this section.
	
	\subsection{Transition Systems}
	
	Transition systems are a model that represent the behavior of a system. A transition system can be regarded as a directed graph, where the nodes of the graph represent the \textit{states} of the system and the edges indicate the \textit{transition} of one state into another. A state encodes information about the system at a certain moment which are formulated as a set of \textit{atomic propositions}. A transition within a transition system thus reflects that the state of the system changes, e.g. the values of parameters have changed, new variables have been introduced or a process has terminated. These transitions can be annotated by \textit{action names} that capture the possible source of change, e.g. the communication with another system or process, like user interaction or input. 
	
	\begin{definition}[Transition System \cite{baier2008principles}]{def:transition system}
		A \textit{transition system} $T$ is a tuple $(S, Act, \rightarrow, I, AP, L)$ where
		\begin{itemize}
			\item $S$ is a set of states,
			\item $Act$ is a set of actions,
			\item $\rightarrow \subseteq S \times Act \times S$ is a transition relation,
			\item $I \subseteq S$ is a set of initial states,
			\item $AP$ is a set of atomic propositions, and
			\item $L: S \rightarrow 2^{AP}$ is a labeling function.
		\end{itemize}
		$T$ is called \textit{finite} if $S$, $Act$, and $AP$ are finite.
	\end{definition}

	The set $AP$ of atomic propositions consists of the specified properties a state $s \in S$ might satisfy. The labeling function $L$ maps a state $s$ to a set $L(s) \in 2^{AP}$ stating the atomic proposition $a\in AP$ is satisfied by state $s$. Based on the set $L(s)$, we can specify that $s$ satisfies a propositional logic formula $\phi$ if the evaluation induced by $L(s)$ fulfills the formula $\phi$. Therefore,
		\[s \models \phi \text{ iff } L(s) \models \phi.\]
	
	The transition relation $\rightarrow$ formally describes how the transition system $T$ evolves starting in an initial state $s_0 \in I$. Thus, the transition $s \xrightarrow{\alpha} s'$ defines that state $s$ evolves to state $s'$ after the action $\alpha$ has been performed. If a state has more than one outgoing transition, the next transition is chosen nondeterministically. This procedure can be continued until a state without any outgoing transitions has been reached. Such a state is called a \textit{terminal state}.
	
	\begin{definition}[Terminal State \cite{baier2008principles}]{def:terminal_state}
		A state $s \in S$ in a transition system $T=(S, Act, \rightarrow, I, AP, L)$ is called \textit{terminal} if and only if 
		\[\bigcup_{\alpha \in Act} \{s'\in S | s \xrightarrow{\alpha} s'\} = \emptyset.\]
	\end{definition}
	
	The resulting sequence of executed transitions starting in an initial state $s_0 \in I$ and either ending in a terminal state $s \in S$ or infinitely prolonging, is called an \textit{execution} of the transition system $T$.
	
	\begin{definition}[Execution]{def:execution}
		Let $T=(S, Act, \rightarrow, I, AP, L)$. A \textit{finite execution} 
		of $T$ is an alternating sequence \[s_0 \alpha_1 s_1 \alpha_2 \dots \alpha_n s_n\] of states and actions such that 
		\begin{itemize}
			\item $s_0 \in I$ is an initial state,
			\item $s_i \xrightarrow{\alpha_{i+1}} s_{i+1}$ for all $0 \leq i < n$, where $n \geq 0$, and
			\item $s_n$ is a terminal state.
		\end{itemize}  
		$n$ is also called the \textit{length} of the execution.
		An \textit{infinite execution} of $T$ is an infinite, alternating sequence \[s_0 \alpha_1 s_1 \alpha_2 s_2 \alpha_3 \dots \] of states and actions such that
		\begin{itemize}
			\item $s_0 \in I$ is an initial state and
			\item $s_i \xrightarrow{\alpha_{i+1}} s_{i+1}$ for all $0 \leq i$.
		\end{itemize} 
	\end{definition}
	
	\begin{definition}[Reachable States \cite{baier2008principles}]{def:reachable_state}
		A state $s \in S$ in a transition system $T=(S, Act, \rightarrow, I, AP, L)$ is called \textit{reachable} in $T$ if there exists an execution of the form \[s_0 \alpha_1 s_1 \alpha_2 \dots \alpha_n s_n = s.\]
		$Reach(T)$ denotes the set of all reachable states in $T$.
	\end{definition}

	For our purpose of model checking pointer-manipulating programs, we focus on the states and the attached atomic propositions of the transition system under consideration, hence, we omit the actions. Multiple transitions between two states with different actions are thus summarized into a single transition. Therefore, the notion of an execution shifts to the notion of \textit{paths} that denote sequences of states that are visited throughout a run.	 
	 
	\begin{definition}[Paths \cite{baier2008principles}]{def:paths}
		A \textit{finite path} $\pi$ of a transition system $T=(S, Act, \rightarrow, I, AP, L)$ is a finite sequence \[s_0 s_1 \dots s_n\] such that 
		\begin{itemize}
			\item $s_0 \in I$ is an initial state, 
			\item $s_i \in \bigcup_{\alpha \in Act} \{s\in S | s_{i-1} \xrightarrow{\alpha} s\}$ for all $0<i\leq n$, where $n \geq 0$, and 
			\item $s_n$ is a terminal state.
		\end{itemize} 
		An \textit{infinite path} $\pi$ is an infinite sequence \[s_0 s_1 s_2 \dots\] such that 
		\begin{itemize}
			\item $s_0 \in I$ is an initial state and 
			\item $s_i \in \bigcup_{\alpha \in Act} \{s\in S | s_{i-1} \xrightarrow{\alpha} s\}$ for all $i > 0$.
		\end{itemize}
		$Paths(T)$ denotes the set of all paths in $T$.
	\end{definition}

	For a path $\pi$, $\pi[i]$ denotes the $i$th state of $\pi$, while $\pi[..i]$ and $\pi[i..]$ denote the $i$th prefix and the $i$th suffix of $\pi$, respectively. Paths display the order of states that are traversed throughout an execution of a transition system. However, the related sets of atomic propositions of the traversed states, which are relevant for model checking, are not observable in the path itself. Therefore, we consider the notion of \textit{traces} which are sequences of sets of atomic propositions that are satisfied along a path $\pi$.
	
	\begin{definition}[Trace \cite{baier2008principles}]{def:trace}
		Let $T=(S, Act, \rightarrow, I, AP, L)$ be a transition system without terminal states.  The \textit{trace} of the finite path $\pi=s_0 s_1 \dots s_n$ is defined as \[trace(\pi)=L(s_0)L(s_1)\dots L(s_n).\] The \textit{trace} of the infinite path $\pi=s_0 s_1 \dots$ is defined as \[trace(\pi)=L(s_0)L(s_1)\dots.\]
		
		$Traces(s)$ denotes the set of traces of paths starting in state $s$ and $Traces(T)$ denotes the set of traces of the initial states of a transition system $T$.\\
	\end{definition}

	The condition that the transition system $T$ does not have any terminal states is not a restriction since for every transition system it is possible to construct an equivalent one without terminal states. This is achieved by adding a new state $s_{stop}$ with a self-loop to the transition system to which all terminal states have a transition. Thus, the resulting system does not contain any terminal states. In the following we assume that a transition system does not have any terminal states.\\
	
	Transition systems are a valid model for computer programs as they represent the control flow of the program and thus reflect the program execution. However, our current model does not consider the hierarchical or even recursive nature of programs containing (recursive) method calls. A transition system would hence depict all states of the program execution in a flat setting where method environments are not differentiated. In order to represent the hierarchical structure of method calls, we employ the concept of \textit{recursive state machines} described in the next section.	

	\subsection{Recursive State Machines}
	
	Often computer programs do not only consist of a linear sequence of commands, but also generate (recursive) calls to methods. Therefore, the execution of these programs contains call- and return-statements to different sections of the input program. In order to capture this hierarchical (or recursive) structure of the system, we introduce the notion of \textit{recursive state machines}, as defined in \cite{alur2001analysis}, that encapsulate each method in an own \textit{component}. Each component consists of a set of \textit{nodes} that are the states of the model and \textit{boxes} that are each mapped to a component in the recursive state machine. A box can be understood as an interface with entry and exit nodes that models the transition into another method environment, e.g. entering a box resembles a method invocation while exiting a box represents the return from a method execution. Edges between states and boxes identify transitions. 
	
	\begin{definition}[Recursive State Machine \cite{alur2001analysis}]{def:rsm}
		A \textit{recursive state machine} (RSM) $\mathcal{A}$ over a finite alphabet $\Sigma$ is given by a tuple $(A_1, ..., A_k)$, where each \textit{component state machine} (CSM) $A_i = (N_i \cup B_i, Y_i, En_i, Ex_i, \delta_i)$, $1 \leq i \leq k$, consists of
		\begin{itemize}
			\item a set $N_i$ of \textit{nodes} and a (disjoint) set $B_i$ of \textit{boxes},
			\item a \textit{labeling} $Y_i: B_i \mapsto \{1, ..., k\}$ that assigns to every box an index $j \in \{1, ..., k\}$ referring to one of the component state machines $A_1, ..., A_k$,
			\item a set of \textit{entry nodes} $En_i \subseteq N_i$,
			\item a set of \textit{exit nodes} $Ex_i \subseteq N_i$, and
			\item a \textit{transition relation} $\delta_i$, where transitions are of the form $(u, \sigma, v)$, where 
			\begin{itemize}
				\item the source $u$ is either a node of $N_i$ or a pair $(b, x)$, where $b$ is a box in $B_i$ and $x$ is an exit node in $Ex_j$ for $j = Y_i(b)$,
				\item the label $\sigma$ is in $\Sigma$, and 
				\item the destination $v$ is either a node in $N_i$ or a pair $(b, e)$, where $b$ is a box in $B_i$ and $e$ is an entry node in $En_j$ for $j = Y_i(b)$.
			\end{itemize}
		\end{itemize}
	\end{definition}
	
	A sample RSM with three components $A_1, A_2, A_3$ is depicted in Figure~\ref{fig:rsm}. The nodes drawn at the border of the components represent the entry and exit nodes, respectively. The arrows depict the transitions between the states of a component as well as between states and boxes. Each box is mapped to a component, e.g. box $b_1$ in component $A_1$ is mapped to component $A_2$ and box $c_2$ in component $A_2$ is mapped to component $A_3$. Thus, entering box $b_1$ or $c_2$ changes the current component under control from component $A_1$ to $A_2$ or from component $A_2$ to $A_3$, respectively. This can be understood as an invocation of program methods where entry nodes represent input arguments to the called method and exit nodes model return values. \\
	
	% example RSM
	\begin{figure}[!h]
		\begin{center}
			%\resizebox{0.7\textwidth}{!}{
			\begin{tikzpicture}
			%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
			[node distance=2cm,thick,
			normal/.style={circle, draw, fill=white, thick, font=\sffamily\Large\bfseries},
			rectstyle/.style={draw, minimum width=7.5cm, minimum height=4.5cm, rounded corners=1.5pt, fill=gray!10}]
			
			\node (a1) at (-3.5, 2.5) {$A_1$};
			\node (rect1) at (0,0) [rectstyle] {};
			\node (u1) at (-3.75,1) [normal, label=180:$u_1$] {};
			\node (u2) at (-3.75,-1) [normal, label=180:$u_2$] {};
			\node (u3) at (-2,-1) [normal, label=-90:$u_3$] {};
			\node (u4) at (3.75, 0) [normal, label=0:$u_4$] {};
			%boxes
			\node (b1) at (0,1) [draw,thick,minimum width=2.5cm,minimum height=1.5cm,fill=gray!20,rounded corners=1.5pt] {$b_1:A_2$};
			\node (b11) at (-1.25,0.75) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (b12) at (-1.25,1.25) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (b13) at (1.25,0.75) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (b14) at (1.25,1.25) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (b2) at (1,-1) [draw,thick,minimum width=2.5cm,minimum height=1.5cm,fill=gray!20,rounded corners=1.5pt] {$b_2:A_3$};
			\node (b21) at (-0.25,-1) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (b22) at (2.25,-1) [normal, minimum size=0.2cm, inner sep=0pt] {};
			% arrows
			\draw[->,shorten >=0.5pt,out=0,in=180] (u1) to (b12);
			\draw[->,shorten >=0.5pt,out=0,in=180] (u2) to (u3);
			\draw[->,shorten >=0.5pt,out=0,in=180] (u3) to (b21);
			\draw[->,shorten >=0.5pt,out=0,in=225] (b22) to (u4);
			\draw[->,shorten >=0.5pt,out=0,in=135] (b14) to (u4);
			\draw[->,shorten >=0.5pt,out=-45,in=225,distance=1.5cm] (b13) to (b11);
			
			\node (a2) at (-3.5, -3) {$A_2$};
			\node (rect2) at (0,-5.5) [rectstyle] {};
			\node (v1) at (-3.75,-4.5) [normal, label=180:$v_1$] {};
			\node (v2) at (-3.75,-6.5) [normal, label=180:$v_2$] {};
			\node (v3) at (3.75, -4.5) [normal, label=0:$v_3$] {};
			\node (v4) at (3.75,-6.5) [normal, label=0:$v_4$] {};
			%boxes
			\node (c1) at (0,-4.5) [draw,thick,minimum width=2.5cm,minimum height=1.5cm,fill=gray!20,rounded corners=1.5pt] {$c_1:A_2$};
			\node (c11) at (-1.25,-4.25) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (c12) at (-1.25,-4.75) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (c13) at (1.25,-4.25) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (c14) at (1.25,-4.75) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (c2) at (0,-6.5) [draw,thick,minimum width=2.5cm,minimum height=1.5cm,fill=gray!20,rounded corners=1.5pt] {$c_2:A_3$};
			\node (c21) at (-1.25,-6.5) [normal, minimum size=0.2cm, inner sep=0pt] {};
			\node (c22) at (1.25,-6.5) [normal, minimum size=0.2cm, inner sep=0pt] {};
			% arrows
			\draw[->,shorten >=0.5pt,out=0,in=180] (v1) to (c11);
			\draw[->,shorten >=0.5pt,out=45,in=180] (v2) to (c12);
			\draw[->,shorten >=0.5pt,out=-45,in=180] (v2) to (c21);
			\draw[->,shorten >=0.5pt,out=45,in=225,distance=2.75cm] (c22) to (c12);
			\draw[->,shorten >=0.5pt,out=0,in=-135] (c22) to (v4);
			\draw[->,shorten >=0.5pt,out=0,in=135] (c13) to (v4);
			\draw[->,shorten >=0.5pt,out=0,in=180] (c14) to (v3);
			
			\node (a3) at (-3.5, -8.5) {$A_3$};
			\node (rect3) at (0,-11) [rectstyle] {};
			\node (w1) at (-3.75,-11) [draw, thick, fill=white, circle, label=180:$w_1$] {};
			\node (w2) at (3.75,-11) [draw, thick, fill=white, circle, label=0:$w_2$] {};
			%boxes
			\node (d) at (0,-11) [draw, thick, fill=gray!20,minimum width=2.5cm,minimum height=1.5cm,rounded corners=1.5pt] {$d:A_1$};
			\node (d1) at (-1.25,-10.75) [draw, thick, fill=white, circle, minimum size=0.2cm, inner sep=0pt] {};
			\node (d2) at (-1.25,-11.25) [draw, thick, fill=white, circle, minimum size=0.2cm, inner sep=0pt] {};
			\node (d3) at (1.25,-11) [draw, thick, fill=white, circle, minimum size=0.2cm, inner sep=0pt] {};
			% arrows
			\draw[->,shorten >=0.5pt,out=0,in=180] (w1) to (d1);
			\draw[->,shorten >=0.5pt,out=0,in=135] (d3) to (w2);
			\draw[->,shorten >=0.5pt,out=-45,in=-135] (w1) to (w2);
			
			\end{tikzpicture}%}
			\caption{A sample recursive state machine. Adapted from \cite{alur2001analysis}.}\label{fig:rsm}
		\end{center}
	\end{figure}
	
	% semantics of RSM
	In order to define the execution of an RSM $\mathcal{A}=(A_1, ..., A_k)$, we first describe the global relation between its component state machines $A_i, 1 \leq i \leq k$. A \textit{global state} of an RSM is a sequence of boxes ending in a node of a component.
	
	\begin{definition}[(Global) State \cite{alur2001analysis}]{def:rsm_semantics}
		A \textit{(global) state} of an RSM $\mathcal{A}=(A_1, ..., A_k)$ is a tuple $(b_1, ..., b_r, u)$, where $b_1, ..., b_r$ are boxes and $u$ is a node. The set $Q$ of global states of $\mathcal{A}$ is $B^*N$, where $B=\bigcup_iB_i$ and $N=\bigcup_iN_i$. A state $(b_1, ..., b_r, u)$ with $b_i \in {B_j}_i$ for $1 \leq i \leq r$ and $u \in N_j$ is \textit{well-formed} if ${Y_j}_i(b_i) = j_{i+1}$ for $1 \leq i < r$ and ${Y_j}_r(b_r) = j$.
	\end{definition}
	
	% TODO A state $(b_1, ..., b_r, u)$ of an RSM $A=(A_1, ..., A_k)$ can also be viewed as a string. 
	% TODO example here
	
	A well-formed state $(b_1, ..., b_r, u)$ of an RSM $\mathcal{A}=(A_1, ..., A_k)$ corresponds to a path through the components $A_j$ of $\mathcal{A}$, where we enter component $A_j$ via box $b_r$ of component ${A_j}_r$.\\
	
	Consider the sample RSM given in Figure~\ref{fig:rsm}. A global state in the sample RSM is given by \[(b_1, c_1, c_1, c_1, c_2, d, b_2, d, u_3),\] where the sequence of boxes protocols which components are visited before reaching the current state $u_3$. The state is well-formed as for every box $b \in \{b_1, b_2, c_1, c_2, d\}$ the labeling function $Y_i$ coincides with the component referred to by the next box in the sequence, e.g., $Y_1(b_1)=A_2$, which is exactly the component in which the following box $c_1$ is defined.\\
	
	In order to transition between global states of an RSM $\mathcal{A}$, we require the notion of a \textit{global transition relation} $\delta$ which enables us to not only transition between states within a CSM $A_j$ as defined by its transition relation $\delta_j$, but also between pairs of CSMs.
	
	\begin{definition}[(Global) Transition Relation \cite{alur2001analysis}]{def:rsm_transitionRelation}
		Let $s=(b_1, ..., b_r, u) \in Q$ be a state with $u\in N_j$ and $b_r \in B_m$ for an RSM $\mathcal{A}=(A_1, ..., A_k)$. A \textit{(global) transition relation} $\delta$ for $\mathcal{A}$ defines $(s, \sigma, s') \in \delta$ if and only if one of the following holds:
		\begin{enumerate}
			\item $(u, \sigma, u') \in \delta_j$ for a node $u'$ of $A_j$ and $s'=(b_1, ..., b_r, u')$.
			\item $(u, \sigma, (b',e))\in \delta_j$ for a box $b'$ of $A_j$ and $s'=(b_1, ..., b_r, b', e)$.
			\item $u$ is an exit-node of $A_j$, $((b_r, u), \sigma, u') \in \delta_m$ for a node $u'$ of $A_m$, and $s'=(b_1, ..., b_{r-1}, u')$.
			\item $u$ is an exit-node of $A_j$, $((b_r, u), \sigma, (b',e)) \in \delta_m$ for a box $b'$ of $A_m$, and $s'=(b_1, ..., b_{r-1}, b', e)$.
		\end{enumerate}
	\end{definition}
	
	Definition~\ref{def:rsm_transitionRelation} defines the possible kinds of transitions between global states $s, s' \in Q$ of an RSM $\mathcal{A}$. Consider the RSM given in Figure~\ref{fig:rsm}. For each case depicted in Definition~\ref{def:rsm_transitionRelation}, we can find an example in order to illustrate the global transition relation: \\
	
	\underline{Case 1} describes the scenario where the source and the destination nodes are both within the same component $A_j$. For instance, the component $A_1$ defines $(u_2, \sigma, u_3) \in \delta_1$, thus, in terms of the global transition relation $\delta$, a valid global transition would be $((b_2,d,u_2), \sigma, (b_2,d, u_3)) \in \delta$.\\ 
	
	\underline{Case 2} depicts that a new component is entered via box $b'$ of $A_j$. Thus, the current node of the destination state $s'$ is the entry-node $e$. An example for this case is given by regarding the global state $(b_1, c_1, c_2, d, u_3)$ which is located in component $A_1$. The local transition relation $\delta_1$ contains the transition $(u_3, \sigma, (b_2, v_1))$. Therefore, globally $((b_1, c_1, c_2, d, u_3), \sigma, (b_1, c_1, c_2, d, b_2, v_1))\in \delta$ which corresponds to  entering component $A_2$ via box $b_2$ and transitioning to state $(b_1, c_1, c_2, d, b_2, v_1)$.\\
	
	\underline{Case 3 and 4} are both exiting component $A_j$ via the exit-node $u$. While case 3 returns to component $A_m$, from where we entered $A_j$ before, case 4 directly enters a new component via box $b'$ of component $A_m$. An example for case 3 is given by the transition $((b_1,c_1,c_2,d,u_4),\sigma, (b_1,c_1,c_2,w_2)) \in \delta$, where we return from component $A_1$ via box $d$ to component $A_3$. If we continue the return action for state $(b_1,c_1,c_2,w_2)$, we get $((b_1,c_1,c_2,w_2), \sigma, (b_1,c_1,c_1,v_2)) \in \delta$ as a sample transition for case 4. The transition describes that we exit component $A_3$ entered via box $c_2$ and directly enter component $A_2$ via box $c_1$ as $((c_2,w_2),\sigma,(c_1, v_2))$ is a valid transition according to $\delta_2$. \\
	
	After defining the terms of global states and the global transition relation for an RSM $\mathcal{A}$, we can summarize these components together with the finite alphabet $\Sigma$ within the concept of a \textit{labeled transition system} $T_{\mathcal{A}}$, which encodes the execution of $\mathcal{A}$.
	
	\begin{definition}[Labeled Transition System \cite{alur2001analysis}]{def:rsm_transitionSystem}
		For an RSM $\mathcal{A}=(A_1, ..., A_k)$, the \textit{labeled transition system} (LTS) $T_\mathcal{A}=(Q, \Sigma, \delta)$ consists of
		\begin{itemize}
			\item a set of global states $Q$, 
			\item a finite alphabet $\Sigma$, and
			\item a global transition relation $\delta$.
		\end{itemize}		
		The LTS of an RSM $\mathcal{A}$ is also called the \textit{unfolding} of $\mathcal{A}$.
	\end{definition}

	The LTS of an RSM is basically the flattening of the hierarchical structure induced by the components and boxes of an RSM. Therefore, an LTS corresponds to our initial definition of a transition system, where the set $Act$ of actions, the set $I$ of initial states, the set $AP$ of atomic propositions, and the labeling function $L$ are implicitly specified by the underlying RSM (cf. Definition~\ref{def:transition system}). 
	
	\subsection{Heap Representation}
	
	After describing recursive state machines as a model for model checking hierarchical programs, we now focus on the representation of the \textit{states} in the transition system. The states under consideration are \textit{heap configurations} holding information on heap objects, program variables, and selectors. Heap configurations are represented by graphs as described in \cite{heinen2015verifying}, where vertices  represent heap objects and edges depict selectors and the mapping of program variables to heap objects. Figure~\ref{fig:dll} illustrates a heap configuration for a doubly-linked list. The list consists of five elements represented by the round vertices of the graph. The selectors \texttt{next} and \texttt{prev} are represented by the edges of the graph. Furthermore, the program variables \texttt{head} and \texttt{tail} are attached to the first and the last vertex of the list, respectively. 
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{0.9\textwidth}{!}{
			\begin{tikzpicture}
			%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
			[node distance=2cm,thick,
			normal/.style={circle, draw, fill=white, thick, minimum width=1cm, font=\sffamily\Large\bfseries},
			rectstyle/.style={draw, minimum width=1.5cm, minimum height=1cm, rounded corners=1.5pt, fill=gray!10}]
			
			\node (a1) at (0,0) [normal] {};
			\node (a2) at (2,0) [normal] {};
			\node (a3) at (4,0) [normal] {};
			\node (a4) at (6,0) [normal] {};
			\node (a5) at (8,0) [normal] {};
			\node (r1) at (-2, 0) [rectstyle] {\texttt{head}};
			\node (r2) at (10, 0) [rectstyle] {\texttt{tail}};
			
			\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
			\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[above] {\texttt{next}} (a3);
			\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[above] {\texttt{next}} (a4);
			\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[above] {\texttt{next}} (a5);
			
			\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
			\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[below] {\texttt{prev}} (a2);
			\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[below] {\texttt{prev}} (a3);
			\draw[->,shorten >=0.5pt] (a5) edge[bend left] node[below] {\texttt{prev}} (a4);
			
			\path[] (r1) edge[line width=0.75mm] node[fill=white, below] {1} (a1);
			\path[] (r2) edge[line width=0.75mm] node[fill=white, below] {1} (a5);
			
			\end{tikzpicture}}
			\caption{Heap configuration of a doubly-linked list. Adapted from \cite{heinen2015verifying}.}\label{fig:dll}
		\end{center}
	\end{figure}

	Pointer-manipulating operations are represented by graph transformations. For instance, executing the operation \texttt{head := tail.prev} on the heap configuration given in Figure~\ref{fig:dll} results in the heap configuration shown in Figure~\ref{fig:dll_op}. 
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{0.75\textwidth}{!}{
				\begin{tikzpicture}
				%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
				[node distance=2cm,thick,
				normal/.style={circle, draw, fill=white, thick, minimum width=1cm, font=\sffamily\Large\bfseries},
				rectstyle/.style={draw, minimum width=1.5cm, minimum height=1cm, rounded corners=1.5pt, fill=gray!10}]
				
				\node (a1) at (0,0) [normal] {};
				\node (a2) at (2,0) [normal] {};
				\node (a3) at (4,0) [normal] {};
				\node (a4) at (6,0) [normal] {};
				\node (a5) at (8,0) [normal] {};
				\node (r1) at (6, 2) [rectstyle] {\texttt{head}};
				\node (r2) at (10, 0) [rectstyle] {\texttt{tail}};
				
				\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[above] {\texttt{next}} (a3);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[above] {\texttt{next}} (a4);
				\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[above] {\texttt{next}} (a5);
				
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[below] {\texttt{prev}} (a2);
				\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[below] {\texttt{prev}} (a3);
				\draw[->,shorten >=0.5pt] (a5) edge[bend left] node[below] {\texttt{prev}} (a4);
				
				\path[] (r1) edge[line width=0.75mm] node[fill=white, right] {1} (a4);
				\path[] (r2) edge[line width=0.75mm] node[fill=white, below] {1} (a5);
				
				\end{tikzpicture}}
			\caption{Modified heap configuration after pointer-operation.}\label{fig:dll_op}
		\end{center}
	\end{figure}
	
	Over the course of the program execution the size of the heap can become unboundedly large, e.g. when new objects are added to the heap. In order to avoid an unbounded size of the heap representation, we exploit the concept of \textit{hypergraphs}. Hypergraphs are similar to the common graph except that they allow for the graph to contain \textit{abstracted} subgraphs. These subgraphs are connected to the concrete part of the heap by \textit{hyperedges}. Hyperedges differ from commonly known edges in the property that they connect arbitrarily many vertices, instead of only two. The number of vertices a hyperedge connects is captured in its \textit{rank}.\\
	
	In order to express the abstracted parts of the heap, we require a \textit{ranked alphabet} $\Sigma = \Sigma_N \uplus \Sigma_T$, where $\Sigma_N$ denotes a finite set of \textit{nonterminal symbols} and $\Sigma_T=Var \uplus Sel$ denotes the terminal symbols including the set $Var$ of variables and the set $Sel$ of selectors. Program variables are of rank one, while selectors are of rank two. Hypergraphs over the alphabet $\Sigma_T$ describe \textit{concrete} heaps that do not contain an abstract part such as the heap depicted in Figure~\ref{fig:dll}.

	
	\begin{definition}[Hypergraph \cite{heinen2015verifyingPhd}]{def:hypergraph}
		Given a finite ranked alphabet $\Sigma = \Sigma_N \uplus \Sigma_T$ with associated ranking function $rk : \Sigma \rightarrow \mathds{N}$. A (labeled) hypergraph over $\Sigma$ is a tuple \[H = (V ,E, att, lab, ext)\]
		where 
		\begin{itemize}
			\item $V$ is a finite set of vertices,
			\item $E$ is a finite set of hyperedges,
			\item the attachment function $att : E \rightarrow V^*$ maps each hyperedge to a sequence of incident vertices, 
			\item the hyperedge-labeling function $lab : E \rightarrow \Sigma$ maps to each edge its label, and 
			\item $ext \in V^*$ is the (possibly empty) sequence of pairwise distinct external vertices. 
		\end{itemize}
		For every $e \in E$, we let $rk(e) = |att(e)|$ and we require $rk(e) = rk(lab(e))$. The set of all hypergraphs over $\Sigma$ is denoted by $HG_{\Sigma}$.
	\end{definition}
	
	An example for a hypergraph with an abstracted subgraph is depicted in Figure~\ref{fig:dll_hyper}. Here, the abstracted subgraph is represented by the hyperedge labeled $DLL$. This indicates that the hyperedge replaces a doubly-linked list of arbitrary length.
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{0.9\textwidth}{!}{
			\begin{tikzpicture}
			%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
			[node distance=2cm,thick,
			normal/.style={circle, draw, fill=white, thick, minimum width=1cm, font=\sffamily\Large\bfseries},
			rectstyle/.style={draw, minimum width=1.5cm, minimum height=1cm, rounded corners=1.5pt, fill=gray!10}]
			
			\node (a1) at (0,0) [normal] {};
			\node (a2) at (2,0) [normal] {};
			\node (a3) at (4,0) [normal] {};
			\node (a4) at (8,0) [normal] {};
			\node (a5) at (10,0) [normal] {};
			\node (r1) at (-2, 0) [rectstyle] {\texttt{head}};
			\node (r2) at (12, 0) [rectstyle] {\texttt{tail}};
			\node (r) at (6, 0) [draw, fill=gray!10, minimum height=1cm] {$DLL$};
			
			\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
			\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[above] {\texttt{next}} (a3);
			\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[above] {\texttt{next}} (a5);
			
			\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
			\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[below] {\texttt{prev}} (a2);
			\draw[->,shorten >=0.5pt] (a5) edge[bend left] node[below] {\texttt{prev}} (a4);
			
			\path[] (r1) edge[line width=0.75mm] node[fill=white, below] {1} (a1);
			\path[] (r2) edge[line width=0.75mm] node[fill=white, below] {1} (a5);
			\path[] (r) edge[] node[fill=white, below] {1} (a3);
			\path[] (r) edge[] node[fill=white, below] {2} (a4);
			
			\end{tikzpicture}}
			\caption{A doubly-linked list with abstracted subgraph represented as a hypergraph. Adapted from \cite{heinen2015verifying}.}\label{fig:dll_hyper}
		\end{center}
	\end{figure}
	
	In order to obtain all possible heap configurations represented by an abstract subgraph, we require the concept of \textit{graph grammars} or more specifically \textit{hyperedge replacement grammars}. Graph grammars are similar to string grammars and define a set of \textit{rules} for graph manipulation. They prescribe how nonterminals can be replaced by hypergraphs. Continuously applying grammar rules to a hypergraph gradually replaces nonterminals by hypergraphs so that concrete heap configurations can be reached eventually.
	
	\begin{definition}[Hyperedge Replacement Grammar \cite{heinen2015verifyingPhd}]{def:hrg}
		A \textit{hyperedge replacement grammar} $G$ over the ranked alphabet $\Sigma$ is a set of production rules of the form $X \rightarrow R$, where $X \in \Sigma_N$ is a nonterminal that forms the left-hand
		side and $R \in HG_{\Sigma}$ is the rule graph, a hypergraph with $|ext_R|=rk(X)$, the right-hand side pf the rule.
	\end{definition}

	The language of a hyperedge replacement grammar contains all concrete hypergraphs that are obtained by repeatedly applying the production rules to a given hypergraph.\\
	
	An example for a hyperedge replacement grammar, that describes the language of all doubly-linked lists with at least two elements, is given in Figure~\ref{fig:dll_grammar}. The first production rule recursively adds an element to the existing list introducing a new nonterminal $DLL$ in order to allow for adding more elements during another production. The second rule terminates the production by replacing the nonterminal $DLL$ by a concrete graph. 
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{0.9\textwidth}{!}{
				\begin{tikzpicture}
				%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
				[node distance=2cm,thick,
				normal/.style={circle, draw, fill=white, thick, minimum width=1cm},
				rectstyle/.style={draw, minimum width=1.5cm, minimum height=1cm, rounded corners=1.5pt, fill=gray!10}]
				
				\node (L) at (0,0) [] {$DLL$};
				\node (arrow) at (2,0) [] {$\rightarrow$};
				
				\node (a1) at (12,0) [normal] {1};
				\node (a2) at (14,0) [normal] {2};
				\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
				
				\draw[] (11,0.75) -- (11,-0.75);
				
				\node (b1) at (4,0) [normal] {1};
				\node (b2) at (6,0) [normal] {};
				\node (DLL) at (8, 0) [draw, fill=gray!10, minimum height=1cm] {$DLL$};
				\node (b3) at (10,0) [normal] {2};
				\draw[->,shorten >=0.5pt] (b1) edge[bend left] node[above] {\texttt{next}} (b2);
				\draw[->,shorten >=0.5pt] (b2) edge[bend left] node[below] {\texttt{prev}} (b1);
				\draw[] (b2) -- node[below] {1} (DLL);
				\draw[] (DLL) -- node[below] {2} (b3);				
				\end{tikzpicture}}
			\caption{A hyperedge replacement grammar for doubly-linked lists. Adapted from \cite{heinen2015verifying}.}\label{fig:dll_grammar}
		\end{center}
	\end{figure}

	Let us consider the hypergraph from Figure~\ref{fig:dll}. We have two options to apply the grammar from Figure~\ref{fig:dll_grammar} to the hypergraph under consideration. Applying the first rule yields the (abstract) hypergraph depicted in Figure~\ref{fig:dll_hyper_r1}, while applying the second rule yields a concrete hypergraph as shown in Figure~\ref{fig:dll_hyper_r2}.
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{0.9\textwidth}{!}{
				\begin{tikzpicture}
				%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
				[node distance=2cm,thick,
				normal/.style={circle, draw, fill=white, thick, minimum width=1cm},
				rectstyle/.style={draw, minimum width=1.5cm, minimum height=1cm, rounded corners=1.5pt, fill=gray!10}]
				
				%start
				\node (a1) at (1,3) [normal] {};
				\node (a2) at (3,3) [normal] {};
				\node (a3) at (5,3) [normal] {};
				\node (a4) at (9,3) [normal] {};
				\node (a5) at (11,3) [normal] {};
				\node (r1) at (-1, 3) [rectstyle] {\texttt{head}};
				\node (r2) at (13, 3) [rectstyle] {\texttt{tail}};
				\node (r) at (7, 3) [draw, fill=gray!10, minimum height=1cm] {$DLL$};
				
				\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[above] {\texttt{next}} (a3);
				\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[above] {\texttt{next}} (a5);
				
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[below] {\texttt{prev}} (a2);
				\draw[->,shorten >=0.5pt] (a5) edge[bend left] node[below] {\texttt{prev}} (a4);
				
				\path[] (r1) edge[line width=0.75mm] node[fill=white, below] {1} (a1);
				\path[] (r2) edge[line width=0.75mm] node[fill=white, below] {1} (a5);
				\path[] (r) edge[] node[fill=white, below] {1} (a3);
				\path[] (r) edge[] node[fill=white, below] {2} (a4);
				
				% rule
				\node (background) at (6,6) [fill=gray!15, minimum height=2.5cm, minimum width=8cm] {};
				\node (b1) at (3,6) [normal] {1};
				\node (b2) at (5,6) [normal] {};
				\node (DLL) at (7,6) [draw, fill=gray!10, minimum height=1cm] {$DLL$};
				\node (b3) at (9,6) [normal] {2};
				\draw[->,shorten >=0.5pt] (b1) edge[bend left] node[above] {\texttt{next}} (b2);
				\draw[->,shorten >=0.5pt] (b2) edge[bend left] node[below] {\texttt{prev}} (b1);
				\draw[] (b2) -- node[below] {1} (DLL);
				\draw[] (DLL) -- node[below] {2} (b3);
				
				\draw[->, dashed, shorten >=0.5pt, out=-90, in=90] (b1) to (a3);
				\draw[->, dashed, shorten >=0.5pt, out=-75, in=90] (b3) to (a4);
				
				\draw[double distance=2, ->] (7,2) -- (7,1);
				
				% result
				\node (a1) at (0,0) [normal] {};
				\node (a2) at (2,0) [normal] {};
				\node (a3) at (4,0) [normal] {};
				\node (a4) at (6,0) [normal] {};
				\node (a5) at (10,0) [normal] {};
				\node (a6) at (12,0) [normal] {};
				\node (r1) at (-2, 0) [rectstyle] {\texttt{head}};
				\node (r2) at (14, 0) [rectstyle] {\texttt{tail}};
				\node (r) at (8, 0) [draw, fill=gray!10, minimum height=1cm] {$DLL$};
				
				\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[above] {\texttt{next}} (a3);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[above] {\texttt{next}} (a4);
				\draw[->,shorten >=0.5pt] (a5) edge[bend left] node[above] {\texttt{next}} (a6);
				
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[below] {\texttt{prev}} (a2);
				\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[below] {\texttt{prev}} (a3);
				\draw[->,shorten >=0.5pt] (a6) edge[bend left] node[below] {\texttt{prev}} (a5);
				
				\path[] (r1) edge[line width=0.75mm] node[fill=white, below] {1} (a1);
				\path[] (r2) edge[line width=0.75mm] node[fill=white, below] {1} (a6);
				\path[] (r) edge[] node[fill=white, below] {1} (a4);
				\path[] (r) edge[] node[fill=white, below] {2} (a5);
				
				\end{tikzpicture}}
			\caption{By applying the first production rule from Figure~\ref{fig:dll_grammar} a list element is added to the (abstract) hypergraph.}\label{fig:dll_hyper_r1}
		\end{center}
	\end{figure}
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{0.9\textwidth}{!}{
				\begin{tikzpicture}
				%	\draw [gray, line width=0.05pt] (0.1,0.1) rectangle (0.2,0.2);
				[node distance=2cm,thick,
				normal/.style={circle, draw, fill=white, thick, minimum width=1cm},
				rectstyle/.style={draw, minimum width=1.5cm, minimum height=1cm, rounded corners=1.5pt, fill=gray!10}]
				
				%start
				\node (a1) at (0,3) [normal] {};
				\node (a2) at (2,3) [normal] {};
				\node (a3) at (4,3) [normal] {};
				\node (a4) at (8,3) [normal] {};
				\node (a5) at (10,3) [normal] {};
				\node (r1) at (-2, 3) [rectstyle] {\texttt{head}};
				\node (r2) at (12, 3) [rectstyle] {\texttt{tail}};
				\node (r) at (6, 3) [draw, fill=gray!10, minimum height=1cm] {$DLL$};
				
				\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[above] {\texttt{next}} (a3);
				\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[above] {\texttt{next}} (a5);
				
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[below] {\texttt{prev}} (a2);
				\draw[->,shorten >=0.5pt] (a5) edge[bend left] node[below] {\texttt{prev}} (a4);
				
				\path[] (r1) edge[line width=0.75mm] node[fill=white, below] {1} (a1);
				\path[] (r2) edge[line width=0.75mm] node[fill=white, below] {1} (a5);
				\path[] (r) edge[] node[fill=white, below] {1} (a3);
				\path[] (r) edge[] node[fill=white, below] {2} (a4);
				
				% rule
				\node (background) at (6,6) [fill=gray!15, minimum height=2.5cm, minimum width=4cm] {};
				\node (b1) at (5,6) [normal] {1};
				\node (b2) at (7,6) [normal] {2};
				\draw[->,shorten >=0.5pt] (b1) edge[bend left] node[above] {\texttt{next}} (b2);
				\draw[->,shorten >=0.5pt] (b2) edge[bend left] node[below] {\texttt{prev}} (b1);
				
				\draw[->, dashed, shorten >=0.5pt, out=-90, in=90] (b1) to (a3);
				\draw[->, dashed, shorten >=0.5pt, out=-90, in=90] (b2) to (a4);
				
				\draw[double distance=2, ->] (6,2) -- (6,1);
				
				%result
				\node (a1) at (1,0) [normal] {};
				\node (a2) at (3,0) [normal] {};
				\node (a3) at (5,0) [normal] {};
				\node (a4) at (7,0) [normal] {};
				\node (a5) at (9,0) [normal] {};
				\node (r1) at (-1, 0) [rectstyle] {\texttt{head}};
				\node (r2) at (11, 0) [rectstyle] {\texttt{tail}};
				
				\draw[->,shorten >=0.5pt] (a1) edge[bend left] node[above] {\texttt{next}} (a2);
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[above] {\texttt{next}} (a3);
				\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[above] {\texttt{next}} (a5);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[above] {\texttt{next}} (a4);
				
				\draw[->,shorten >=0.5pt] (a2) edge[bend left] node[below] {\texttt{prev}} (a1);
				\draw[->,shorten >=0.5pt] (a3) edge[bend left] node[below] {\texttt{prev}} (a2);
				\draw[->,shorten >=0.5pt] (a5) edge[bend left] node[below] {\texttt{prev}} (a4);
				\draw[->,shorten >=0.5pt] (a4) edge[bend left] node[below] {\texttt{prev}} (a3);
				
				\path[] (r1) edge[line width=0.75mm] node[fill=white, below] {1} (a1);
				\path[] (r2) edge[line width=0.75mm] node[fill=white, below] {1} (a5);
				
				\end{tikzpicture}}
			\caption{By applying the second production rule from Figure~\ref{fig:dll_grammar} a concrete hypergraph is obtained.}\label{fig:dll_hyper_r2}
		\end{center}
	\end{figure}	

	Figures~\ref{fig:dll_hyper_r1} and ~\ref{fig:dll_hyper_r2} display the forward application of production rules on a hypergraph also called \textit{concretisation} as an abstract fragment is replaced by a (more) concrete subgraph. A concretisation step can yield more than one concrete hypergraph if several production rules are applicable. Thus, abstraction of subgraphs yield an over-approximation of the current set of concrete hypergraphs, since information is lost during abstraction. It is not always possible to uniquely identify the initial hypergraph of which the abstracted graph has been derived of. Therefore, concretisation needs to consider all possible hypergraphs. In fact, the application of the production rules of the hyperedge replacement grammar for doubly-linked lists in Figures~\ref{fig:dll_hyper_r1} and ~\ref{fig:dll_hyper_r2} is an example for a case where more than one rule is applicable. \\
	
	In contrast to concretisation, \textit{abstraction} describes the backward application of production rules such that a subgraph is replaced by a nonterminal. Abstraction hence allows us to represent possibly unboundedly large graphs in a finite manner.\\
	
	% TODO require check for embeddings of right hand sides
	
	Concluding with the concept of hypergraphs and hyperedge replacement grammars we specified the relevant framework for model checking pointer-manipulating programs. We model the program execution by recursive state machines capturing the hierarchical nature of method calls, while hypergraphs offer a finite representation of heap configurations that constitute the states of the model under consideration. The second ingredient to model checking is the formal definition of the properties the model is to be validated for. Here, we focus on \textit{linear temporal logic} described in the following section.
	
	\section{Linear Temporal Logic}\label{sec:ltl}
	 
	First proposed by Pnueli in 1977, \textit{Linear Temporal Logic} (LTL) is a modal temporal logic suited to describe \textit{linear-time properties}. 
	Linear-time properties specify requirements on paths (or rather their traces) and can be understood as a set of (infinite) words over a set $AP$ of atomic propositions.
	
	\begin{definition}[Linear-Time Property \cite{baier2008principles}]{def:lt_property}
		A \textit{linear-time property} over the set of atomic propositions $AP$ is a subset of $(2^{AP})^{\omega}$.
	\end{definition}

	Thus, a linear-time property can be interpreted as a language of infinite words defined over the alphabet $2^{AP}$.\\
	
	The satisfaction relation $\models$ for linear-time properties defines that a transition system $T$ satisfies a linear-time property if and only if all traces of $T$ are included in the set $P$ meaning that every trace of $T$ is a word in the language induced by $P \subseteq (2^{AP})^{\omega}$.
	
	\begin{definition}[Satisfaction Relation for Linear-Time Properties \cite{baier2008principles}]{def:satis_lt_property}
		Let $P$ be a linear-time property over $AP$ and $T=(S, Act, \rightarrow, I, AP, L)$ a transition system. Then, $T$ \textit{satisfies} $P$, denoted $T \models P$, iff $Traces(T) \subseteq P$. A state $s \in S$ satisfies $P$, denoted $s \models P$, iff $Traces(s) \subseteq P$.
	\end{definition}
	
	Linear-time properties can be specified by LTL formulae that encode temporal specifications for paths. In LTL, time is understood as a discrete time-unit where a point in time is followed by a single time-unit. In contrast to LTL, CTL (Computation Tree Logic) considers tree-like paths which can split into alternative courses. Here, we focus on LTL formulae.\\
	
	LTL formulae are composed of three components: the boolean operators \textit{negation} ($\neg$) and \textit{conjunction} ($\wedge$), the temporal operators \textit{next} ($\bigcirc$) and \textit{until} ($\textbf{\textit{U}}$), and a set of atomic propositions $AP$. Atomic propositions are state labels of a transition system, which express properties that hold for a single state, e.g., "$i=1$". Formally, the set of LTL formulae is defined as follows:
	
	\begin{definition}[Syntax of LTL \cite{baier2008principles}]{def:ltl_syntax}
		Given a set $AP$ of atomic propositions with $a \in AP$, \textit{LTL formulae} are recursively defined by
		\begin{equation*}		
			\varphi := \texttt{\textup{true}} \mid a \mid \neg \varphi \mid \varphi_1 \wedge \varphi_2 \mid \bigcirc \varphi \mid \varphi_1 \textbf{\textup{U}} \varphi_2.
		\end{equation*}
	\end{definition}

	Further temporal operators that are commonly used, but are not included in the definition of LTL formulae, are the temporal modalities \textit{eventually}  ($\lozenge$), \textit{globally} ($\square$), and \textit{release} ($\textbf{\textup{R}}$). They can be derived using the operators given in Definition~\ref{def:ltl_syntax} as follows: 
	
	\begin{align*}		
		\lozenge \varphi &:= \texttt{\textup{true}} \textbf{\textup{U}} \varphi\\
		\square \varphi &:= \neg \lozenge\neg\varphi\\
		\varphi_1 \textbf{\textup{R}} \varphi_2 &:= \neg(\neg\varphi_1 \textbf{\textup{U}} \neg \varphi_2).
	\end{align*}
	
	Before formally defining the satisfaction relation for LTL formulae and a transition system $T$, we first constitute an intuitive understanding of temporal operators by visualizing their semantics in Figure~\ref{fig:temporal_ops}.\\
	
	\begin{figure}[h!]
		\begin{center}		
			\begin{tikzpicture}
				[node distance=2cm,thick,
				normal/.style={circle, draw, fill=white, thick, font=\sffamily\Large\bfseries}]
				
				\node (1) at (2,0) [normal, label=90:$1$, label=-90:$\texttt{\textup{true}}$] {};
				\node (2) at (3.5,0) [normal, label=90:$2$, label=-90:$\texttt{\textup{true}}$] {};
				\node (3) at (5,0) [normal, label=90:$i$, label=-90:$\texttt{\textup{true}}$] {};
				\node (4) at (6.5,0) [normal, label=90:$i+1$, label=-90:$\texttt{\textup{true}}$] {};
				\node (5) at (8,0) {};
				\draw[->,shorten >=0.5pt,out=0,in=180] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (2) to (3);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);	
				
				\node () at (0,0) {$\texttt{\textup{true}}$};
				\node () at (11.5,0) [align=left,text width=6cm]{$\pi \models \texttt{\textup{true}}$ since every state satisfies $\texttt{\textup{true}}$. Thus, $\varphi=\texttt{\textup{true}}$ is fulfilled by every path $\pi$.};	
				
				\node (1) at (2,-2) [normal, label=90:$1$, label=-90:$\models a$] {};
				\node (2) at (3.5,-2) [normal, label=90:$2$] {};
				\node (3) at (5,-2) [normal, label=90:$3$] {};
				\node (4) at (6.5,-2) [normal, label=90:$4$] {};
				\node (5) at (8,-2) {};
				\draw[->,shorten >=0.5pt,out=0,in=180] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);	
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);	
				
				\node () at (0,-2) {$a \in AP$};
				\node () at (11.5,-2) [align=left,text width=6cm]{$\pi \models a$ if the first state of path $\pi$ satisfies the proposition $a$.};	
				
				\node (1) at (2,-4) [normal, label=90:$1$, label=-90:$\neg\varphi$] {};
				\node (2) at (3.5,-4) [normal, label=90:$2$] {};
				\node (3) at (5,-4) [normal, label=90:$3$] {};
				\node (4) at (6.5,-4) [normal, label=90:$4$] {};
				\node (5) at (8,-4) {};
				\draw[->,shorten >=0.5pt,out=0,in=180] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);	
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);		
				
				\node () at (0,-4) {$\neg\varphi$};
				\node () at (11.5,-4) [align=left,text width=6cm]{$\pi \models \neg \varphi$ if the first state of path $\pi$ does not satisfy $\varphi$.};
				
				\node (1) at (2,-6) [normal, label=90:$1$, label=-90:$\varphi_1 \wedge \varphi_2$] {};
				\node (2) at (3.5,-6) [normal, label=90:$2$] {};
				\node (3) at (5,-6) [normal, label=90:$3$] {};
				\node (4) at (6.5,-6) [normal, label=90:$4$] {};
				\node (5) at (8,-6) {};
				\draw[->,shorten >=0.5pt,out=0,in=180] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);	
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);	
				
				\node () at (0,-6) {$\varphi_1 \wedge \varphi_2$};
				\node () at (11.5,-6) [align=left,text width=6cm]{$\pi \models \varphi_1 \wedge \varphi_2$ if the first state of path $\pi$ satisfies both formulae $\varphi_1$ and $\varphi_2$ at the same time.};	
				
				\node (1) at (2,-8) [normal, label=90:$1$] {};
				\node (2) at (3.5,-8) [normal, label=90:$2$, label=-90:$\varphi$] {};
				\node (3) at (5,-8) [normal, label=90:$3$] {};
				\node (4) at (6.5,-8) [normal, label=90:$4$] {};
				\node (5) at (8,-8) {};
				\draw[->,shorten >=0.5pt,out=0,in=180] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);	
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);		
				
				\node () at (0,-8) {$\bigcirc \varphi$};
				\node () at (11.5,-8) [align=left,text width=6cm]{$\pi \models \bigcirc \varphi$ if the next state in path $\pi$ satisfies the formula $\varphi$.};		
				
				\node (1) at (2,-10) [normal, label=90:$1$, label=-90:$\varphi_1$] {};
				\node (2) at (3.5,-10) [normal, label=90:$i-1$,label=-90:$\varphi_1$] {};
				\node (3) at (5,-10) [normal, label=90:$i$,label=-90:$\varphi_2$] {};
				\node (4) at (6.5,-10) [normal, label=90:$i+1$] {};
				\node (5) at (8,-10) {};
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);		
				
				\node () at (0,-10) {$\varphi_1 \textbf{\textup{U}} \varphi_2$};
				\node () at (11.5,-10) [align=left,text width=6cm]{$\pi \models \varphi_1 \textbf{\textup{U}} \varphi_2$ if $\varphi_1$ holds for states $1$ to $i-1$ and there exists a state $i$ that satisfies $\varphi_2$.};
				
				\node (1) at (2,-12) [normal, label=90:$1$,label=-90:$\neg\varphi$] {};
				\node (2) at (3.5,-12) [normal, label=90:$i-1$,label=-90:$\neg\varphi$] {};
				\node (3) at (5,-12) [normal, label=90:$i$,label=-90:$\varphi$] {};
				\node (4) at (6.5,-12) [normal, label=90:$i+1$] {};
				\node (5) at (8,-12) {};
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);
				
				\node () at (0,-12) {$\lozenge\varphi$};
				\node () at (11.5,-12) [align=left,text width=6cm]{$\pi \models \lozenge \varphi$ if there exists a state $i$ on path $\pi$ which satisfies $\varphi$.};
				
				\node (1) at (2,-14) [normal, label=90:$1$,label=-90:$\varphi$] {};
				\node (2) at (3.5,-14) [normal, label=90:$2$,label=-90:$\varphi$] {};
				\node (3) at (5,-14) [normal, label=90:$3$,label=-90:$\varphi$] {};
				\node (4) at (6.5,-14) [normal, label=90:$4$,label=-90:$\varphi$] {};
				\node (5) at (8,-14) {};
				\draw[->,shorten >=0.5pt,out=0,in=180] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);	
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);	
				
				\node () at (0,-14) {$\square \varphi$};
				\node () at (11.5,-14) [align=left,text width=6cm]{$\pi \models \square \varphi$ if all states on path $\pi$ satisfy $\varphi$.};
				
				\node (1) at (2,-16) [normal, label=90:$1$, label=-90:$\varphi_2$] {};
				\node (2) at (3.5,-16) [normal, label=90:$i-1$,label=-90:{$\varphi_2$}] {};
				\node (3) at (5,-16) [normal, label=90:$i$,label=-90:{$\varphi_2,\varphi_1$}] {};
				\node (4) at (6.5,-16) [normal, label=90:$i+1$] {};
				\node (5) at (8,-16) {};
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);
				
				\node () at (0,-16) {$\varphi_1 \textbf{\textup{R}} \varphi_2$};
				\node () at (11.5,-16) [align=left,text width=6cm]{$\pi \models \varphi_1 \textbf{\textup{R}} \varphi_2$ if $\varphi_2$ holds for states $1$ to $i-1$ and there exists a state $i$ that satisfies $\varphi_1$.};
				
				\node (1) at (2,-18) [normal, label=90:$1$, label=-90:$\varphi_2$] {};
				\node (2) at (3.5,-18) [normal, label=90:$2$,label=-90:$\varphi_2$] {};
				\node (3) at (5,-18) [normal, label=90:$3$,label=-90:$\varphi_2$] {};
				\node (4) at (6.5,-18) [normal, label=90:$4$,label=-90:$\varphi_2$] {};
				\node (5) at (8,-18) {};
				\draw[->,shorten >=0.5pt,out=0,in=180] (1) to (2);	
				\draw[->,shorten >=0.5pt,out=0,in=180] (2) to (3);
				\draw[->,shorten >=0.5pt,out=0,in=180] (3) to (4);	
				\draw[->,shorten >=0.5pt,out=0,in=180,dashed] (4) to (5);
				
				\node () at (0,-18) {$\varphi_1 \textbf{\textup{R}} \varphi_2$};
				\node () at (11.5,-18) [align=left,text width=6cm]{$\pi \models \varphi_1 \textbf{\textup{R}} \varphi_2$ if $\varphi_2$ holds for all states of $\pi$.};
		\end{tikzpicture}
		\caption{Intuitive semantics of temporal operators.}\label{fig:temporal_ops}
		\end{center}
	\end{figure}	
	
	The following definition captures the relation between linear-time properties and LTL formulae as the latter can also be interpreted as words over the alphabet $2^{AP}$.
	
	\begin{definition}[Semantics of LTL (Interpretation over Words) \cite{baier2008principles}]{def:ltl_words_semantics}
		Let $\varphi$ be an LTL formula over $AP$. The linear-time property induced by $\varphi$ is \[Words(\varphi) = \{\sigma \in (2^{AP})^{\omega}\text{ }|\text{ }\sigma \models \varphi\}\] where the satisfaction relation $\models \subseteq (2^{AP})^{\omega} \times LTL$ is the smallest relation with the following properties 
		\begin{align*}
			\sigma &\models \texttt{true}\\
			\sigma &\models a &&\text{ iff } a \in A_0, \text{ where } \sigma = A_0A_1A_2\dots\\
			\sigma &\models \varphi_1 \wedge \varphi_2 &&\text{ iff } \sigma \models \varphi_1 \text{ and } \sigma \models \varphi_2\\
			\sigma &\models \neg \varphi &&\text{ iff } \sigma \nvDash \varphi\\
			\sigma &\models \bigcirc \varphi &&\text{ iff } \sigma[1\dots]=A_1A_2A_3 \dots \models \varphi\\
			\sigma &\models \varphi_1 \text{\textbf{U}} \varphi_2 &&\text{ iff } \exists j \geq 0. \sigma[j \dots ] \models \varphi_2 \text{ and } \sigma[i\dots] \models \varphi_1, \forall 0 \leq i < j.
		\end{align*}
	\end{definition}
	
	The interpretation of LTL formulae over words can be used to describe the semantics of LTL formulae over paths and states of a transition system $T$.
	
	\begin{definition}[Semantics of LTL over Paths and States \cite{baier2008principles}]{def:ltl_paths_semantics}
		Let $T=(S, Act, \rightarrow, I, AP, L)$ be a transition system without terminal states, and let $\varphi$ be an LTL-formula over $AP$.\\
		For an infinite path $\pi$ of $T$, the satisfaction relation is defined by \[\pi \models \varphi \text{ iff } trace(\pi) \models \varphi.\]
		For a state $s \in S$, the satisfaction relation $\models$ is defined by \[s \models \varphi \text{ iff } (\forall \pi \in Paths(T). \pi \models \varphi).\]
		$T$ satisfies $\varphi$, denoted $T \models \varphi$, if $Traces(T) \subseteq Words(\varphi).$
	\end{definition}

	From Definition~\ref{def:ltl_paths_semantics}, it follows that \[T \models \varphi \text{ iff } s_0 \models \varphi, \forall s_0 \in I.\]
	
	Based on the satisfaction relation of LTL formulae over paths and states, we can specify the semantics of LTL for a transition system $T$.

	\begin{definition}[Semantics of LTL \cite{baier2008principles}]{def:ltl_semantics}
		Given an LTL formula $\varphi$, a concrete transition system $T$, and a path $\pi \in Paths(T)$, the model relation $\models$ for LTL formulae is defined by
		\begin{align*}
			\pi &\models \texttt{\textup{true}}   \\
			\pi &\models a &&\Leftrightarrow \pi[1] \models a\\			
			\pi &\models \neg \varphi &&\Leftrightarrow \textup{ not } \pi[1] \models \varphi\\
			\pi &\models \varphi_1 \wedge \varphi_2 &&\Leftrightarrow (\pi \models \varphi_1) \textup{ and } (\pi \models \varphi_2)\\
			\pi &\models \bigcirc \varphi &&\Leftrightarrow \pi[2...] \models \varphi\\
			\pi &\models \varphi_1 \textbf{\textup{U}} \varphi_2 &&\Leftrightarrow \exists i \geq 1.(\pi[i...] \models \varphi_2 \wedge (\forall 1\leq k < i. \pi[k...] \models \varphi_1)).
		\end{align*}
		
		Given a state $s\in S$, $s \models \varphi$ if for all $\pi \in Paths(T)$ it holds that $\pi \models \varphi$. For a transition system $T$, $T \models \varphi$ if for all $\pi \in Paths(T)$ it holds that $\pi \models \varphi$. %TODO adjust abbreviation
	\end{definition}

	For the operators \textit{eventually}  ($\lozenge$), \textit{globally} ($\square$), and \textit{release} ($\textbf{\textup{R}}$), the semantics are defined similarly:
	
	\begin{align*}
		\pi &\models \lozenge \varphi &&\Leftrightarrow \exists i \geq 1.\pi[i...] \models \varphi\\
		\pi &\models \square \varphi &&\Leftrightarrow \forall i \geq 1. \pi[i...] \models \varphi\\
		\pi &\models \varphi_1 \textbf{\textup{R}} \varphi_2  &&\Leftrightarrow \forall i \geq 1.\pi[i...]\models \varphi_2 \textup{ or } \\
		& &&\exists i \geq 1.(\pi[i...] \models \varphi_1 \wedge (\forall 1\leq k < i. \pi[k...] \models \varphi_2)).
	\end{align*}
	
	The following LTL formulae are examples for specifying properties for model checking pointer-manipulating programs.
	\[\bigcirc \{\texttt{SLList}\}\]
	where \texttt{SLList} is assumed to be an atomic proposition describing that the heap is a singly-linked list. Hence, the formula states that the heap of the next state is a singly-linked list. Another example is the formula
	\[\square \{\texttt{SLList}\}\]
	which requires the heap of every state to be a singly-linked list. Thus, any state not satisfying the atomic proposition \texttt{SLList} falsifies the formula $\square \{\texttt{SLList}\}$. The formula \[\square \lozenge \{\texttt{terminated}\} \rightarrow \square \lozenge \{\texttt{SLList}\}\] includes another atomic proposition, \texttt{terminated}, that describes that a state is a terminating state. Thus, the above formula states that the heap is a singly-linked list upon termination of the program.\\

	Two LTL formulae are semantically equivalent if they evaluate to the same results under all interpretations.	For every LTL formula, there exists an equivalent formula in \textit{positive normal form} (PNF), where negations are only allowed on the level of literals \cite{baier2008principles}.
	
	\begin{definition}[Positive Normal Form \cite{baier2008principles}]{def:ltl_pnf}
		Given a set $AP$ of atomic propositions with $a \in AP$, LTL formulae in \textit{positive normal form} (PNF) are defined by
		\begin{equation*}		
		\varphi := \texttt{\textup{true}} \mid \texttt{\textup{false}} \mid a \mid \neg a \mid \varphi_1 \wedge \varphi_2 \mid \varphi_1 \vee \varphi_2 \mid \bigcirc \varphi \mid \varphi_1 \textbf{\textup{U}} \varphi_2 \mid \varphi_1 \textbf{\textup{R}} \varphi_2.
		\end{equation*}
	\end{definition}
	
	The existence of an equivalent PNF formula for every LTL formula is due to the following equivalences that allow to push negations inside \cite{heinen2015verifyingPhd}:
	
	\begin{align*}
		\neg \neg \varphi &= \varphi\\
		\neg \texttt{false} &= \texttt{true}\\
		\neg (\varphi_1 \wedge \varphi_2) &= \neg \varphi_1 \vee \neg \varphi_2 \\
		\neg \bigcirc \varphi &= \bigcirc \neg \varphi \\
		\neg (\varphi_1 \textbf{\textup{U}} \varphi_2) &= \neg \varphi_1 \textbf{\textup{R}} \neg \varphi_2
	\end{align*}
	
	As an example consider the LTL formula \[\square \lozenge \{\texttt{terminated}\} \rightarrow \square \lozenge \{\texttt{SLList}\}\] where \texttt{terminated} and \texttt{SLList} are atomic propositions. \texttt{terminated} describes that a state is a terminating state and \texttt{SLList} states that the heap of a state is a singly-linked list. An equivalent formula in PNF is achieved by the following equivalences:
	\begin{align*}
		&\square \lozenge \{\texttt{terminated}\} \rightarrow \square \lozenge \{\texttt{SLList}\} \\
		\equiv \quad &\neg(\square \lozenge \{\texttt{terminated}\}) \vee (\square \lozenge \{\texttt{SLList}\}) \qquad &(\text{definition of } \rightarrow) \\
		\equiv \quad &\neg(\square (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{terminated}\})) \\&\vee (\square (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{SLList}\})) \qquad &(\text{definition of } \lozenge) \\
		\equiv \quad &\neg(\neg\lozenge\neg (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{terminated}\}))\\ &\vee (\neg\lozenge\neg (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{SLList}\})) \qquad &(\text{definition of } \square) \\
		\equiv \quad &\neg(\neg(\text{\texttt{true}}  \text{\textbf{ U }} \neg (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{terminated}\})))\\ &\vee (\neg(\text{\texttt{true}} \text{\textbf{ U }} \neg (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{SLList}\}))) \qquad &(\text{definition of } \lozenge) \\
		\equiv \quad &\neg(\neg\text{\texttt{true}}  \text{\textbf{ R }} (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{terminated}\}))\\ &\vee (\neg\text{\texttt{true}} \text{\textbf{ R }} (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{SLList}\})) \qquad &(\text{duality of } \text{\textbf{U}} \text{ and } \text{\textbf{R}}) \\
		\equiv \quad &\text{\texttt{true}}  \text{\textbf{ U }} (\neg\text{\texttt{true}} \text{\textbf{ R }} \neg\{\texttt{terminated}\}) \\&\vee (\neg\text{\texttt{true}} \text{\textbf{ R }} (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{SLList}\})) \qquad &(\text{duality of } \text{\textbf{U}} \text{  and} \text{\textbf{R}}) \\
	\end{align*}	
	
	\chapter{Hierarchical Model Checking}
	
	One of the main challenges in model checking programs with method calls is that we do not only need to consider the state space of the main method, but also the state spaces induced by method executions, denoted as \textit{procedure state spaces}. Here, we face two main difficulties:
	\begin{itemize}
		\item How can we finitely represent the state space of a program with recursive method calls, at best avoiding repetitions in the state space?
		\item How can we efficiently model check procedure state spaces, at best avoiding checking a procedure state space multiple times? 
	\end{itemize}
	
	In this chapter, we introduce two approaches to model checking LTL properties for pointer-manipulating programs with method calls. The underlying state space of procedural programs is a hierarchical one where each procedure contributes an own state space that is connected to nodes of other state spaces reflecting method invocation. In a flat setting, where hierarchy is not actively considered, this corresponds to an edge connecting the calling state with the "entry" state of the procedure state space. For the flat setting, the first section of this chapter presents an on-the-fly LTL model checking approach that constructs a proof structure based on a set of tableaux rules that reflect the semantics of LTL \cite{bhat1995efficient}. \\
	
	As a flat state space does not capture the modularity of methods, we represent the state space as a recursive state machine. In the second section of this chapter, we present an LTL model checking approach for RSMs by Yannakakis et al. which is based on the automata-based approach by Vardi and Wolper as described in \cite{vardi1986automata}.\\
	
	Based on the presented algorithms, we introduce our modified approaches to hierarchical model checking in the sequel of this thesis.
	
	\section{Tableaux Construction}\label{sec:tableaux}
	
	This section presents the on-the-fly approach by Grumberg et al. that constructs a \textit{proof structure} based on a set of \textit{tableaux rules} in order to show whether a formula $\varphi$ is satisfied by a transition system $T$. \\
	
	A proof structure is a directed graph $(V,E)$, where the set of vertices $V$ are composed of a set of \textit{assertions} $\Lambda$ and the set $E$ of edges contains the edge $(\lambda_1, \lambda_2)$ between two assertions $\lambda_1$ and $\lambda_2$ if the underlying tableaux contains the rule $\frac{\lambda_1}{\lambda_2}$.
	
	\begin{definition}[Proof Structure \cite{bhat1995efficient}]{def:ps}
		A \textit{proof structure} for $\lambda \in \Lambda$ is a tuple $(V,E)$ with $V \subseteq (\Lambda \; \cup \ \texttt{true})$ and $E \subseteq V \times V$, such that for any $\lambda'$ it holds that $\lambda'$ is reachable from $\lambda$ and that the successors of $\lambda'$ are the ones that result from applying some of the rules, i.e. \[(\lambda_1, \lambda_2) \in E \qquad \text{ iff } \qquad \frac{\lambda_1}{\lambda_2 \quad s \dots}.\]
	\end{definition}
	
	The underlying tableaux rules for the proof structure are specified in the following. They model the semantics of LTL.
	
	\begin{align*}
	&(R^{\models}) \quad \frac{s \vdash \Phi \cup \{a\}}{\texttt{true}} \; \text{ if } s \models a \\[1.5ex]
	&(R^{\nvDash}) \quad \frac{s \vdash \Phi \cup \{a\}}{s \vdash \Phi} \; \text{ if } s \nvDash a \\[1.5ex]
	&(R^{\vee}) \quad \frac{s \vdash \Phi \cup \{\varphi_1 \vee \varphi_2\}}{s \vdash \Phi \cup \{\varphi_1\} \cup \{\varphi_2\}}\\[1ex]
	&(R^{\wedge}) \quad \frac{s \vdash \Phi \cup \{\varphi_1 \wedge \varphi_2\}}{s \vdash \Phi \cup \{\varphi_1\} \qquad s \vdash \Phi\cup \{\varphi_2\}}\\[1.5ex]
	&(R^{\text{\textbf{U}}}) \quad \frac{s \vdash \Phi \cup \{\varphi_1 \text{\textbf{U}} \varphi_2\}}{s \vdash \Phi \cup \{\varphi_2, \varphi_1\} \qquad s \vdash \Phi\cup \{\varphi_2, \bigcirc(\varphi_1 \text{\textbf{U}} \varphi_2)\}}\\[1.5ex]
	&(R^{\text{\textbf{R}}}) \quad \frac{s \vdash \Phi \cup \{\varphi_1 \text{\textbf{R}} \varphi_2\}}{s \vdash \Phi \cup \{\varphi_2\} \qquad s \vdash \Phi\cup \{\varphi_1, \bigcirc(\varphi_1 \text{\textbf{R}} \varphi_2)\}}\\[1.5ex]
	&(R^{\bigcirc}) \quad \frac{s \vdash \{\bigcirc \varphi_1, \dots, \bigcirc \varphi_n\}}{s_1 \vdash \{\varphi_1, \dots, \varphi_n\} \qquad \dots \qquad s_m \vdash \{\varphi_1, \dots, \varphi_n\}}\\
	\end{align*}
	
	The rules for the operators \textbf{U} and \textbf{R} follow from the expansion law for LTL formulae \cite{baier2008principles}. Accordingly,
	\[\varphi_1 \text{\textbf{U}} \varphi_2 \equiv \varphi_2 \vee (\varphi_1 \wedge \bigcirc (\varphi_1 \text{\textbf{U}} \varphi_2))\] and
	\[\varphi_1 \text{\textbf{R}} \varphi_2 \equiv \varphi_2 \wedge (\varphi_1 \vee \bigcirc (\varphi_1 \text{\textbf{R}} \varphi_2)).\]	
	
	The vertices $V$ of a proof structure $(V,E)$ are assertions of the form $s \vdash \Phi$, where $s$ is a state in $T$ and $\Phi$ is a set of LTL formulae. An assertion $s \vdash \Phi$ holds if at least one formula $\varphi \in \Phi$ is satisfied by the state $s$. Thus, an assertion can be interpreted as a verification goal that aims at proving that $s\models \bigvee_{\varphi \in \Phi}\varphi$. In order to do so, the assertion is broken down into subgoals according to the tableaux rules. By proving a sequence of subgoals the validity of the assertion $\lambda$ can be concluded from the validity of the subgoals. Hence, the proof structure of an assertion $\lambda$ contains all subgoals of $\lambda$. \\
	
	The rules $(R^{\text{\textbf{U}}})$ and $(R^{\text{\textbf{R}}})$ can introduce cycles into the proof structure if $\varphi_1$ is fulfilled for every state in the underlying transition system for formulae of the form $\varphi_1 \text{\textbf{U}} \varphi_2$ or $\varphi_1 \text{\textbf{R}} \varphi_2$ $\varphi_1$, while no state fulfills $\varphi_2$. Therefore, a cycle in a proof structure represents an \textit{infinite path} in the underlying state space. In an infinite path $\varphi_1 \text{\textbf{U}} \varphi_2$ can never be fulfilled whereas $\varphi_1 \text{\textbf{R}} \varphi_2$ is fulfilled according to the definition of \textbf{R}. Consequently, a cycle in the proof structure originating from successively applying rule $(R^{\text{\textbf{U}}})$ evaluates to a violated assertion, while a cycle arising from applying rule $(R^{\text{\textbf{R}}})$ fulfills the subgoal. The other rules specified in the tableaux cannot introduce cycles as their application reduces the size of the formulae. \\
	
	In the following, we describe when a proof structure $(V,E)$ for an assertion $\lambda$ can be concluded to be \textit{successful} \cite{bhat1995efficient}:
	
	\begin{itemize}
		\item If $s \vdash \emptyset \in V$, then $(V,E)$ is unsuccessful as an empty assertion can never be fulfilled.
		\item $\lambda \in V$ is a leaf of the proof structure if there is no $\lambda' \in V$ with $(\lambda, \lambda') \in E$. A leaf $\lambda$ is called successful if $\lambda = \texttt{true}$.
		\item An infinite path $\lambda_1 \lambda_2 \dots$ in $(V,E)$ is called successful if and only if there exists a position $i\in \mathds{N}$ with $\varphi_1 \text{\textbf{R}} \varphi_2 \in \lambda_i$ and for all $j \geq i$ it holds that $\varphi \notin \lambda_j$.
		\item The proof structure $(V,E)$ is called successful if every lead as well as every of its infinite paths is successful.
	\end{itemize} 
	
	Theorem \ref{thm:tableaux_correct} states that the tableaux construction is indeed a suitable procedure to model check a transition system $T$ for an LTL formula $\varphi$ as the success of the proof structure $s \vdash \{\varphi\}$ for a state $s$ in $T$ coincides with the validity of $T \models \varphi$.
	
	\begin{theorem}[Correctness of the Tableaux Construction \cite{bhat1995efficient}]{thm:tableaux_correct}
		Given a concrete transition system $T=(S, Act, \rightarrow, I, AP, L)$ with $s\in S$ and an LTL formula $\varphi$. Let $(V,E)$ be the proof structure for $s \vdash \{\varphi\}$. Then it holds that $s \models \varphi$ iff $(V,E)$ is successful.
	\end{theorem}
	
	%TODO example
	
	Consider a method for reversing a singly-linked list given by
	
	\begin{lstlisting}[language=Java]
	public static SLList reverse(SLList head) {
	
	SLList reversedList = null;
	SLList current = head;
	
	while (current != null) {
	SLList next = current.next;
	current.next = reversedList;
	reversedList = current;
	current = next;
	}
	
	return reversedList;
	}
	\end{lstlisting}
	
	Figure~\ref{fig:reverseSLL_tableaux} shows the state space of reversing a singly-linked list with two elements according to the method \texttt{reverse}. For this state space, we want to check whether the formula $\varphi=\square \lozenge \{\texttt{terminated}\} \rightarrow \square \lozenge \{\texttt{SLList}\}$ is satisfied. From Section~\ref{sec:ltl} we know that \[\varphi \equiv \text{\texttt{true}}  \text{\textbf{ U }} (\neg\text{\texttt{true}} \text{\textbf{ R }} \neg\{\texttt{terminated}\}) \vee (\neg\text{\texttt{true}} \text{\textbf{ R }} (\text{\texttt{true}} \text{\textbf{ U }} \{\texttt{SLList}\}))\] in PNF.
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{\textwidth}{!}{
				\begin{tikzpicture}
				[node distance=2cm,thick,
				normal/.style={circle, draw, fill=white, thick},
				rectstyle/.style={draw, minimum width=7cm, minimum height=2cm, rounded corners=1.5pt, fill=gray!10},
				var/.style={draw, rounded corners=1.5pt, fill=white}]
				
				%state 1
				\node (back1) at (1,0) [rectstyle] {};
				\node (text) at (-2.25,0.75) {$s_1$};
				\node (1) at (0,0) [normal] {};
				\node (2) at (1,0) [normal] {};
				\node (3) at (2,0) [normal] {};
				\node (head) at (-1.5,0) [var] {\texttt{head}};
				\node (null) at (3.5,0) [var] {\texttt{null}};
				\draw[->,shorten >=0.5pt] (1) edge[bend left] node[above] {\texttt{n}} (2);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[above] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);
				
				%state 2
				\node (back2) at (10,0) [rectstyle] {};
				\node (text) at (6.75,0.75) {$s_2$};
				\node (1) at (9,0) [normal] {};
				\node (2) at (10,0) [normal] {};
				\node (3) at (11,0) [normal] {};
				\node (head) at (7.5,0) [var] {\texttt{head}};
				\node (null) at (12.5,0) [var] {\texttt{null}};
				\node (current) at (11,-0.65) [var] {\texttt{current}};
				\node (revList) at (12.5,0.65) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend left] node[above] {\texttt{n}} (2);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[above] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (3);
				\draw (revList) to (3);
				
				%state 3
				\node (back3) at (10,-3) [rectstyle] {};
				\node (text) at (6.75,-2.25) {$s_3$};
				\node (1) at (9,-3) [normal] {};
				\node (2) at (10,-3) [normal] {};
				\node (3) at (11,-3) [normal] {};
				\node (head) at (7.5,-3) [var] {\texttt{head}};
				\node (null) at (12.5,-3) [var] {\texttt{null}};
				\node (current) at (7.5,-3.65) [var] {\texttt{current}};
				\node (revList) at (12.5,-3.65) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend left] node[above] {\texttt{n}} (2);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[above] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (1);
				\draw (revList) to (3);
				
				%state 4
				\node (back4) at (1,-3) [rectstyle] {};
				\node (text) at (-2.25,-2.25) {$s_4$};
				\node (1) at (0,-3) [normal] {};
				\node (2) at (1,-3) [normal] {};
				\node (3) at (2,-3) [normal] {};
				\node (head) at (-1.5,-3) [var] {\texttt{head}};
				\node (null) at (3.5,-3) [var] {\texttt{null}};			
				\node (current) at (-1.5,-3.65) [var] {\texttt{current}};
				\node (revList) at (3.5,-3.65) [var] {\texttt{revList}};
				\node (next) at (1,-3.65) [var] {\texttt{next}};
				\draw[->,shorten >=0.5pt] (1) edge[bend left] node[above] {\texttt{n}} (2);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[above] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);			
				\draw (current) to (1);
				\draw (revList) to (3);
				\draw (next) to (2);		
				
				%state 5
				\node (back5) at (1,-6) [rectstyle] {};
				\node (text) at (-2.25,-5.25) {$s_5$};
				\node (1) at (0,-6) [normal] {};
				\node (2) at (1,-6) [normal] {};
				\node (3) at (2,-6) [normal] {};
				\node (head) at (-1.5,-6) [var] {\texttt{head}};
				\node (null) at (3.5,-6) [var] {\texttt{null}};	
				\node (next) at (1,-5.35) [var] {\texttt{next}};		
				\node (current) at (-1.5,-6.65) [var] {\texttt{current}};
				\node (revList) at (3.5,-6.65) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend right] node[below] {\texttt{n}} (3);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[below] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);			
				\draw (current) to (1);
				\draw (revList) to (3);
				\draw (next) to (2);
				
				%state 6
				\node (back6) at (10,-6) [rectstyle] {};
				\node (text) at (6.75,-5.25) {$s_6$};
				\node (1) at (9,-6) [normal] {};
				\node (2) at (10,-6) [normal] {};
				\node (3) at (11,-6) [normal] {};
				\node (head) at (7.5,-6) [var] {\texttt{head}};
				\node (null) at (12.5,-6) [var] {\texttt{null}};
				\node (current) at (7.5,-6.65) [var] {\texttt{current}};
				\node (next) at (10,-5.35) [var] {\texttt{next}};
				\node (revList) at (8,-5.35) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend right] node[below] {\texttt{n}} (3);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[below] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (1);
				\draw (revList) to (1);
				\draw (next) to (2);
				
				%state 7
				\node (back7) at (10,-9) [rectstyle] {};
				\node (text) at (6.75,-8.25) {$s_7$};
				\node (1) at (9,-9) [normal] {};
				\node (2) at (10,-9) [normal] {};
				\node (3) at (11,-9) [normal] {};
				\node (head) at (7.5,-9) [var] {\texttt{head}};
				\node (null) at (12.5,-9) [var] {\texttt{null}};
				\node (current) at (8,-8.35) [var] {\texttt{current}};
				\node (next) at (10,-8.35) [var] {\texttt{next}};
				\node (revList) at (7.5,-9.65) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend right] node[below] {\texttt{n}} (3);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[below] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (2);
				\draw (revList) to (1);
				\draw (next) to (2);
				
				%state 8
				\node (back8) at (1,-9) [rectstyle] {};
				\node (text) at (-2.25,-8.25) {$s_8$};
				\node (1) at (0,-9) [normal] {};
				\node (2) at (1,-9) [normal] {};
				\node (3) at (2,-9) [normal] {};
				\node (head) at (-1.5,-9) [var] {\texttt{head}};
				\node (null) at (3.5,-9) [var] {\texttt{null}};
				\node (current) at (1,-8.35) [var] {\texttt{current}};
				\node (next) at (3,-8.35) [var] {\texttt{next}};
				\node (revList) at (-1.5,-9.65) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend right] node[below] {\texttt{n}} (3);
				\draw[->,shorten >=0.5pt] (2) edge[bend left] node[below] {\texttt{n}} (3);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (2);
				\draw (revList) to (1);
				\draw (next) to (3);
				
				%state 9
				\node (back9) at (1,-12) [rectstyle] {};
				\node (text) at (-2.25,-11.25) {$s_9$};
				\node (1) at (0,-12) [normal] {};
				\node (2) at (1,-12) [normal] {};
				\node (3) at (2,-12) [normal] {};
				\node (head) at (-1.5,-12) [var] {\texttt{head}};
				\node (null) at (3.5,-12) [var] {\texttt{null}};
				\node (current) at (1,-11.35) [var] {\texttt{current}};
				\node (next) at (3,-11.35) [var] {\texttt{next}};
				\node (revList) at (-1.5,-12.65) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend right] node[below] {\texttt{n}} (3);
				\draw[->,shorten >=0.5pt] (2) edge[bend right] node[below] {\texttt{n}} (1);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (2);
				\draw (revList) to (1);
				\draw (next) to (3);
				
				%state 10
				\node (back10) at (10,-12) [rectstyle] {};
				\node (text) at (6.8,-11.25) {$s_{10}$};
				\node (1) at (9,-12) [normal] {};
				\node (2) at (10,-12) [normal] {};
				\node (3) at (11,-12) [normal] {};
				\node (head) at (7.5,-12) [var] {\texttt{head}};
				\node (null) at (12.5,-12) [var] {\texttt{null}};
				\node (current) at (11,-11.35) [var] {\texttt{current}};
				\node (next) at (12.75,-11.35) [var] {\texttt{next}};
				\node (revList) at (9,-11.35) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend right] node[below] {\texttt{n}} (3);
				\draw[->,shorten >=0.5pt] (2) edge[bend right] node[below] {\texttt{n}} (1);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (2);
				\draw (revList) to (2);
				\draw (next) to (3);
				
				%state 11
				\node (back11) at (10,-15) [rectstyle] {};
				\node (text) at (6.8,-14.25) {$s_{11}$};
				\node (1) at (9,-15) [normal] {};
				\node (2) at (10,-15) [normal] {};
				\node (3) at (11,-15) [normal] {};
				\node (head) at (7.5,-15) [var] {\texttt{head}};
				\node (null) at (12.5,-15) [var] {\texttt{null}};
				\node (current) at (12,-15.65) [var] {\texttt{current}};
				\node (next) at (12,-14.35) [var] {\texttt{next}};
				\node (revList) at (10,-14.35) [var] {\texttt{revList}};
				\draw[->,shorten >=0.5pt] (1) edge[bend right] node[below] {\texttt{n}} (3);
				\draw[->,shorten >=0.5pt] (2) edge[bend right] node[below] {\texttt{n}} (1);
				\draw (head) to (1);
				\draw (null) to (3);
				\draw (current) to (3);
				\draw (revList) to (2);
				\draw (next) to (3);
				
				\draw[->,shorten >=0.5pt] (-3,0) --  (back1);
				\draw[->,shorten >=0.5pt] (back1) -- node[above,align=center] {\texttt{revList=}\\\texttt{null}} node[below,align=center] {\texttt{current=}\\\texttt{null}} (back2);
				\draw[->,shorten >=0.5pt] (back2) -- node[right,align=center] {\texttt{current=head}}  (back3);
				\draw[->,shorten >=0.5pt] (back3) -- node[above,align=center] {\texttt{next=}\\\texttt{current.n}} (back4);
				\draw[->,shorten >=0.5pt] (back4) -- node[left,align=center] {\texttt{current.n=revList}} (back5);
				\draw[->,shorten >=0.5pt] (back5) -- node[above,align=center] {\texttt{revList=}\\\texttt{current}} (back6);
				\draw[->,shorten >=0.5pt] (back6) -- node[right,align=center] {\texttt{current=next}} (back7);
				\draw[->,shorten >=0.5pt] (back7) -- node[above,align=center] {\texttt{next=}\\\texttt{current.n}} (back8);
				\draw[->,shorten >=0.5pt] (back8) -- node[left,align=center] {\texttt{current.n=revList}} (back9);
				\draw[->,shorten >=0.5pt] (back9) -- node[above,align=center] {\texttt{revList=}\\\texttt{current}} (back10);
				\draw[->,shorten >=0.5pt] (back10) -- node[right,align=center] {\texttt{current=next}} (back11);
				\draw[->,shorten >=0.5pt,in=180,out=180] (back11) edge[in=180,out=0,loop left] (back11);
				\end{tikzpicture}}
			\caption{State space for reversing a singly-linked list. Adapted from \cite{heinen2015verifyingPhd}.}\label{fig:reverseSLL_tableaux}
		\end{center}
	\end{figure}
	%TODO add example for tableaux	
	
	\section{Automata-Based Model Checking} 
	
	Recursive programs can be modeled as recursive state machines that capture the hierarchical nature of the underlying state space. Based on RSMs, LTL model checking can be performed to check whether an RSM, and thus the represented system, satsfies a temporal property. This section presents the basic ideas of the automata-theoretic approach to model checking transition systems for LTL specifications as introduced in \cite{vardi1986automata} by Vardi and Wolper. The algorithm can be adapted for RSMs. For an LTL formula $\varphi$ and a transition system $T$ the algorithm by Vardi and Wolper either returns "yes" if $T \models \varphi$ or "no" and a failure trace of the path that violates the formula $\varphi$. \\
	
	The approach is based on the fact that every LTL formula $\varphi$ can be represented by a \textit{nondeterministic Büchi automaton}.
	
	\begin{definition}[Nondeterministic Büchi Automaton \cite{baier2008principles}]{def:nba}
		A \textit{nondeterministic Büchi automaton} (NBA) $\mathcal{B}$ is a tuple $\mathcal{B}=(Q, \Sigma, \delta, Q_0, F)$ where 
		\begin{itemize}
			\item $Q$ is a finite set of states,
			\item $\Sigma$ is an alphabet,
			\item $\delta: Q \times \Sigma \rightarrow 2^Q$ is a transition function,
			\item $Q_0 \subseteq Q$ is a set of initial states, and
			\item $F \subseteq Q$ is a set of \textit{accept} or final states, called the \textit{acceptance set}. 
		\end{itemize}
		A run $\sigma = B_0B_1B_2 \dots \in \Sigma^{\omega}$ of an NBA $\mathcal{B}$ is an infinite sequence $q_0q_1q_2 \dots$ of states in $\mathcal{B}$ such that $q_0 \in Q_0$ and $q_i \xrightarrow{B_i}q_{i+1}$ for $i \geq 0$. A run $q_0q_1q_2 \dots$ is \textit{accepting} if $q_i \in F$ for infinitely many indices $i \in \mathds{N}$. The \textit{accepted} language of $\mathcal{B}$ is 
		\[\mathcal{L}_{\omega}(\mathcal{B})=\{\sigma \in \Sigma^{\omega} | \text{ there exists an accepting run for } \sigma \text{ in } \mathcal{B}\}.\] 
		The size $|\mathcal{B}|$ of $\mathcal{B}$ is defined as the number of states and transitions in $\mathcal{B}$.
	\end{definition}
	
	\begin{theorem}[]{thm:nba}
		For any LTL formula $\varphi$ over $AP$ there exists an NBA $\mathcal{B}_{\varphi}$ with \[Words(\varphi)=\mathcal{L}(\mathcal{B}_{\varphi})\] which can be constructed in time and space $2^{\mathcal{O}(|\varphi|)}$. \cite{baier2008principles}
	\end{theorem}

	The automata-based approach for model checking an LTL formulae $\varphi$ for a transition system $T$ is based on the idea to find a path $\pi$ in $T$ that satisfies the formula $\neg \varphi$. If such path is found, then it follows that $T \nvDash \varphi$ since a path is found that satisfies the negation of the desired formula $\varphi$. Hence, the answer to the model checking procedure is "no" and $\pi$ is returned as a failure trace. Otherwise, it can be concluded that $T \models \varphi$ as no path is found to satisfy $\neg \varphi$. This conclusion is valid, since
	
	\begin{align*}
		T \models \varphi & \text{ iff } Traces(T) \subseteq Words(\varphi)\\
		& \text{ iff } Traces(T) \cap ((2^{AP})^{\omega} \ Words(\varphi)) = \emptyset\\
		& \text{ iff } Traces(T) \cap Words(\neg \varphi) = \emptyset.	
	\end{align*}
	
	Therefore, for NBA $\mathcal{B}_{\neg \varphi}$
	\[T \models \varphi \text{ iff } Traces(T) \cap \mathcal{L}(\mathcal{B}_{\neg \varphi}) = \emptyset\] as $\mathcal{L}(\mathcal{B}_{\neg \varphi}) = Words(\neg \varphi)$.

	\begin{algorithm}
		\caption{Automata-Based LTL Model Checking}\label{algo:automataMC}
		\begin{algorithmic} 
			\REQUIRE finite transition system $T$, LTL formula $\varphi$
			\ENSURE "yes", if $T \models \varphi$; "no" and a counterexample, otherwise 
			\STATE Construct an NBA $\mathcal{B}_{\neg \varphi}$ for $\neg \varphi$.
			\STATE Construct the product transition system $T'=T \otimes \mathcal{B}_{\neg \varphi}$.
			\IF{$\exists$ path $\pi$ in $T'$ satisfying the acceptance condition of $\mathcal{B}$}
			\RETURN "no" and counterexample
			\ELSE
			\RETURN "yes"
			\ENDIF
		\end{algorithmic}
	\end{algorithm}

	The automata-based approach is described in Algorithm~\ref{algo:automataMC}. In a first step, an NBA $\mathcal{B}_{\neg \varphi}$ is constructed for the formula $\neg \varphi$. Thereafter, the product transition system $T'=T \otimes \mathcal{B}_{\neg \varphi}$ is constructed from the transition system $T$ and the NBA $\mathcal{B}_{\neg \varphi}$. The problem of determining whether a path $\pi$ exists in $T$ that satisfies the acceptance condition of the product transition system $T'$, can be reduced to checking for  emptiness of the intersection of the sets of $Traces(T)$ and $\mathcal{L}(\mathcal{B}_{\neg \varphi})$. If $Traces(T) \cap \mathcal{L}(\mathcal{B}_{\neg \varphi}) = \emptyset$, then there does not exist any path $\pi$ in $T$ that satisfies $\neg \varphi$ and hence does not violate $\varphi$. However, if the intersection is not empty, then an according path $\pi$ is detected and $\varphi$ is violated.\\
	
	The automata-based approach can be adapted to recursive state machines as described in \cite{alur2001analysis}. In this context, the notion of \textit{recursive Büchi automata} is introduced that augment RSMs with Büchi-acceptance conditions.\\ %TODO explain more
	
	In order to improve the performance of the algorithm, it is possible to execute the automata-based approach in an on-the-fly manner. That is, instead of sequentially computing the automata $\mathcal{B}_{\neg \varphi}$ and the product transition system $T'$, both automata are computed on demand as long as no path $\pi$ is found that satisfies $\neg \varphi$. Hence, the automata do not need to be constructed entirely if a violating path can be detected at an early stage.\\
	
	However, LTL model checking is still computationally hard and it can be shown that the LTL model checking problem is PSPACE-complete \cite{baier2008principles}.
	
	\begin{theorem}[]{thm:ltl_complexity}
		The LTL model checking problem is PSPACE-complete.
	\end{theorem}
	
	As the automaton-construction of the NBA $\mathcal{L}(\mathcal{B}_{\neg \varphi})$ as well as the product construction are quite costly in practice, %TODO source?
	we approach automata-based model checking by combining the structures of recursive state machines and the procedures of the \textit{tableaux construction} for model checking LTL formulae. We depict the tableaux construction in the next section. The resulting algorithm from our combined approach is presented in Chapter~\ref{chp:hmc}.	
	
	\chapter{On-The-Fly Hierarchical Model Checking}\label{chp:otf}
	
	The tableaux construction is an on-the-fly approach to model checking transition systems for an LTL formula $\varphi$. In this chapter, we describe how we adapt the tableaux construction by Grumberg et al. to  hierarchical tableaux construction that accounts for model checking of hierarchical structures including procedure state spaces. In a next step, we present the implementation of hierarchical tableaux construction in the \textsc{Attestor} framework and conclusively evaluate our proceedings.
	
	\section{Algorithm}
	
	Given a transition system (or state space) $T$ and a set of LTL formulae $\Phi$, the goal of the hierarchical tableaux construction is to verify whether the state space, including procedure state spaces induced by the method executions, satisfies the temporal properties specified by $\Phi$. We assume the state space to be flat and finite. The basis of the algorithm is the tableaux construction by Grumberg et al. that we extend by the following functionalities:
	\begin{itemize}
		\item Interweave state space construction and state space model checking,
		\item Model check procedure state spaces, and
		\item Create model checking contracts for procedure state spaces in order to reuse model checking results that have been computed beforehand.
	\end{itemize}	

	The algorithm is based on the procedure \texttt{generateAndCheck} (cf. Figure~\ref{fig:otfHMC}) that validates a set $\Phi$ of formulae for an input program based on the algorithm of the \textsc{Attestor} state space generation described in Section~\ref{sec:attestor}. After initialising the state space and the proof structure, the procedure \texttt{generateAndCheck} starts constructing the proof structure based on the tableaux rules defined in Section~\ref{sec:tableaux}. Successor states are generated on demand if the proof structure needs to be extended to further states due to validating $\bigcirc$-formulae. State generation involves that the statement of the current state is executed. In contrast to the \texttt{Attestor} state space generation, statement execution, and therefore state generation, includes model checking of the generated state. Hence, statements that invoke method executions trigger the model checking of procedure state spaces, that is, the procedure \texttt{generateAndCheck} is executed on the calling state of the method and the current set $\Phi'$ of formulae. It follows that a hierarchy of calls to \texttt{generateAndCheck} is constructed where each level represents the model checking procedure of a method execution. Once state space generation and model checking is completed for a method execution, the successor states and model checking results are returned to the above lying level. Model checking results include information on whether any formula is violated as well as the updated set of formulae for which the successor states need to be checked for. The model checking results are stored in contracts of the form
	
	\[(HC_{in}, \Phi) \mapsto (\Phi', \delta_{0/1}, \pi),\]
	
	where $HC_{in}$ denotes the input heap configuration for which the set $\Phi$ of formulae is to be validated. The tuple $(HC_{in}, \Phi)$ is mapped to a tuple of model checking results containing the resulting set $\Phi'$ of formulae to be checked for possible successor states, a boolean value $\delta_{0/1}$ that indicates whether model checking was successful, and a failure trace $\pi$ in case any formulae is found to be violated. Model checking contracts are stored in the context of \textit{procedure contracts} which unambiguously define the executed method. Procedure contracts capture the overall effect of a procedure by defining pairs of pre- and post-conditions. Pre- and post-conditions specify the heap configurations before and after the execution of a procedure, respectively. Details on procedure contracts are described in \cite{jansen2014generating}. Thus, model checking contracts can be used to avoid repetitive model checking of a procedure state space for a set of input formulae.\\
	
	Together with the set $\Phi'$ of formulae, the resulting successor states induce new assertions that are added to the proof structure. If the proof structure is (still) successful, then the new assertions are added to the proof structure and the procedure is continued. Otherwise, a violating path has been found and the proof structure is declared to be unsuccessful. Hence, the proof structures of the above lying state spaces can be aborted as a violating path has been found such that it can be concluded that the set of formulae $\Phi$ is not satisfied for the complete program state space. Thus, an early termination of the model checking procedure is possible that does not require building the complete state space. The concept of the hierarchical tableaux construction is depicted in Figure~\ref{fig:otfHMC}. \\
	
	\begin{figure}[!h]
		\begin{center}
			\resizebox{\textwidth}{0.75\textheight}{
				\begin{tikzpicture}
				[node distance=2cm,thick,
				normal/.style={circle, draw, fill=white, thick},
				rectstyle/.style={draw, minimum width=6cm, minimum height=10cm, rounded corners=1.5pt, fill=gray!10},
				phase/.style={draw, minimum width=5cm, minimum height=1cm, rounded corners=1.5pt, fill=white}]
				
				\node (back1) at (1,-7) [draw, minimum width=25cm, minimum height=26cm, rounded corners=1.5pt,fill=blue!10] {};
				\node (check) at (-9.5, 6.25) {\textbf{generateAndCheck}};
				\node (back) at (0,-10.5) [rectstyle] {};
				\node (exec) at (-3.25, -13.5) [rotate=90] {\textbf{abstract execution}};
				
				\node (init) at (0,9) [phase] {add initial states};
				\node (init2) at (0,7.5) [phase] {add initial assertions};
				
				\node (ps1) at (0, 4) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
				\node (ps1text) at (ps1) [align=center] {proof str.\\ successful\\ \& !empty};
				
				\node (build) at (0,0.5) [phase] {build proof structure};
				
				\node (ps2) at (0, -3) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
				\node (ps2text) at (ps2) [align=center] {$\bigcirc$-formulae\\ empty};
				
				\node (p1) at (0,-6.5) [phase] {concretise};
				\node (p2) at (0,-8) [phase] {execute statement};
				\node (p22) at (0,-9.5) [phase,fill=yellow] {model check};
				
				\node (ps3) at (6, -9.5) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
				\node (ps3text) at (ps3) [align=center] {statement\\invokes\\ method};
				
				\node (ps4) at (11, -9.5) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
				\node (ps4text) at (ps4) [align=center] {$\exists$\\model checking\\ contract};				
				
				\node (p3) at (0,-11.5) [phase] {rectify};
				\node (p4) at (0,-13) [phase] {abstract};
				\node (p5) at (0,-14.5) [phase] {label};
				
				\node (d1) at (0, -17.5) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
				\node (d1text) at (d1) [align=center] {subsumed\\ by existing\\ state};
				
				\node (add) at (-6,-17.5) [draw, minimum width=3cm, minimum height=1cm, rounded corners=1.5pt, fill=white] {add to state space};
				
				\node (ps5) at (-6, -8) [rectangle,draw,xscale=8,yscale=8,rotate=45, fill=white] {};
				\node (ps5text) at (ps5) [align=center] {model\\checking\\successful};
				
				\node (addassert) at (-4,-4.5) [draw, minimum width=3cm, minimum height=1cm, rounded corners=1.5pt, fill=white] {add assertion};
				
				\node (abort) at (-8,-4.5) [draw, minimum width=3cm, minimum height=1cm, rounded corners=1.5pt, fill=white] {abort proof str.};
				
				\draw[->,shorten >=0.5pt] (0,10) to (init);
				\draw[->,shorten >=0.5pt] (init) to (init2);
				\draw[->,shorten >=0.5pt] (init2) to (0,5.5);
				%proof structure successful
				\draw[->,shorten >=0.5pt] (0,2.5) -- node[right] {\texttt{yes}} (build);
				\draw[->,shorten >=0.5pt] (1.5,4) -- node[above] {\texttt{no}} (14.5,4);
				\node (return) at (16,4) [align=center] {return\\model checking\\results};
				\draw[->,shorten >=0.5pt] (build) to (0,-1.5);
				%next formulae empty
				\draw (-1.5,-3) -- node[above] {\texttt{yes}} (-6,-3);
				\draw[->,shorten >=0.5pt] (0,-4.5) -- node[right] {\texttt{no}} (p1);
				\draw[->,shorten >=0.5pt] (p1) to (p2);
				\draw[->,shorten >=0.5pt] (p2) to (p22);
				%model check
				\draw[->,shorten >=0.5pt] (p22) to (4.5,-9.5);
				\draw[->,shorten >=0.5pt] (7.5,-9.5) -- node[above] {\texttt{yes}} (9.5,-9.5);
				%exists model checking contract
				\draw (6,-11) to (6,-11.5);
				\draw[->,shorten >=0.5pt] (6,-11.5) -- node[above] {\texttt{no}} (p3);
				\draw (11,-11) edge (11,-11.5);
				\draw[->,shorten >=0.5pt] (11,-11.5) -- node[above] {\texttt{yes}} (p3);
				\draw (12.5,-9.5) -- node[above] {\texttt{no}} (14,-9.5);
				\draw (14,-9.5) to (14,9);
				\draw[->,shorten >=0.5pt] (14,9) to (init);
				\node (checkProcedure) at (16,-7) [align=center] {generate\\and check\\called procedure\\state space};
				
				\draw[->,shorten >=0.5pt] (p3) to (p4);
				\draw[->,shorten >=0.5pt] (p4) to (p5);			
				\draw[->,shorten >=0.5pt] (p5) to (0,-16);
				
				\draw[->,shorten >=0.5pt] (-1.5,-17.5) -- node[above] {\texttt{no}} (add);
				\draw (0,-19) edge (0,-19.5);
				\draw (0,-19.5) -- node[above] {\texttt{yes}} (-10,-19.5);
				\draw (-10,-19.5) edge (-10,-8);
				\draw[->,shorten >=0.5pt] (-10,-8) to (-7.5,-8);
				
				\draw[->,shorten >=0.5pt] (add) to (-6,-9.5);
				\draw (-6,-6.5) to (-6,-6);
				\draw (-8,-6) to (-4,-6);
				\draw[->,shorten >=0.5pt] (-8,-6) -- node[left] {\texttt{no}} (abort);
				\draw[->,shorten >=0.5pt] (-4,-6) -- node[right] {\texttt{yes}} (addassert);
				\draw (addassert) to (-4,-3.5);
				\draw (abort) to (-8,-3.5);
				\draw (-8,-3.5) to (-4,-3.5);
				\draw (-6,-3.5) to (-6,4);
				\draw[->,shorten >=0.5pt] (-6,4) to (-1.5,4);
				
				\end{tikzpicture}}
			\caption{On-the-fly hierarchical model checking by a hierarchical tableaux construction.}\label{fig:otfHMC}
		\end{center}
	\end{figure}	

	%TODO reference example from introduction and show that algorithm will find error that previous version cannot
	
	The correctness of the on-the-fly tableaux construction for hierarchical state spaces follows from the correctness of the tableaux construction \cite{bhat1995efficient} and the correctness of the state space generation algorithm defined in \cite{arndt2018let}.
	
	\section{Implementation}
	%TODO add UML diagram / architecture?
	We implemented the on-the-fly tableaux construction for hierarchical state spaces within the \textsc{Attestor} framework written in \textsc{Java}. The code can be found at \url{https://github.com/SallyChau/master_thesis/tree/master/attestor}. As both state space generation and model checking are performed, the on-the-fly hierarchical model checking algorithm encompasses \textsc{Attestor}'s present state space generation and model checking phases. We refer to the new phase as the \textit{on-the-fly model checking phase}.\\
	
	The implementation of the on-the-fly model checking phase requires two main adaptations in the \textsc{Attestor} framework. First, we need to adapt the tableaux construction algorithm such that it does not work on a complete state space, but rather successively demands for new states as soon as they are required for the building the proof structure. Second, we require a possibility to query for a list of successor states for a given state $s$. \\
	
	Let us turn to the on-the-fly tableaux construction first. The \texttt{ProofStructure} class implements the tableaux construction for a given state space and an LTL formula. By calling the method \texttt{build} on a given state space and an LTL formula to be checked, the proof structure is constructed. This method requires a completely generated state space to operate on. This class \texttt{OnTheFlyProofStructure} modifies the current implementation such that it is capable of constructing the proof structure for an on-the-fly constructed state space. Instead of requiring a completely generated state space, the on-the-fly version solely requires initial assertions. These are expanded according to the tableaux rules until an assertion which only contains $\bigcirc$-formula is reached. Since the underlying state space is not present, the proof structure cannot be continued. Thus, we require the generation of the successors of the current state. At this point, the control is handed to the \texttt{StateSpaceGenerator}, where \textsc{Attestor}'s state space generation is performed.\\
	
	By calling the \texttt{generate} method of the class \texttt{StateSpaceGenerator} the state space generation for the input program is performed and the completely generated state space is returned upon termination. For the on-the-fly approach, we do not require the complete state space, but rather a list of successor states for a given state $s$. We realize this functionality in the class \texttt{OnTheFlyStateSpaceGenerator} which generates the successors to a  state returned by the previously constructed proof structure. The list of successors are then communicated back to the proof structure by adding new assertions and reentering the model checking loop (cf. Figure~\ref{fig:otfHMC}).\\
	
	Further adjustments are required in the labeling of states in procedure state spaces which maps an atomic proposition $a \in AP$ to a state $s$ if $s \models a$.  Up until now, only the states of the top-level state space are labeled, as procedure state spaces were not considered in the tableaux construction. However, in order to model check procedure state spaces, the corresponding states need to be labeled as well. When a method is invoked at a state $s$, the heap configuration of the state $s$ is adapted to the scope of the invoked method such that local variables are excluded. Thus, we obtain a \textit{scoped heap configuration}. This might produce faulty results when labeling states within procedure state spaces, as parts of the heap are disguised. For example, consider the property of the heap being a singly-linked list. Assume a heap configuration, where this is in fact true. Now, if we enter a method \texttt{foo()} that does nothing, the heap will be scoped to an empty heap, so that the property, that the heap is a singly-linked list, is violated. Thus, the state will not be labeled with the corresponding atomic proposition, resulting in a negative outcome of the model checking procedure despite the fact that the heap is still a singly-linked list outside of the method call. Hence, in order to account for procedure state labeling, we introduce the notion of a \textit{scope hierarchy} which tracks which parts of the heap have been excluded for state space generation. As there might be a hierarchy of method calls, the heap configuration under consideration might have been scoped multiple times. Thus, the collection of scopes is summarized in the scope hierarchy. Now, before computing the labels for a state under consideration, the scope hierarchy is applied back to the state in reversed order, such that the original heap configuration is restored. Based on the resulting state, the corresponding atomic propositions are determined.
	
	\section{Evaluation}
	
	Model checking of hierarchical state spaces requires model checking of the procedure state spaces. \textsc{Attestor}'s current model checking approach only considers the top-level state space for model checking and thus disregards possible erroneous behavior within method executions. The on-the-fly approach on hierarchical model checking solves this gap by model checking procedure state spaces during their generation. Thus, the algorithm successfully interweaves state space generation and state space model checking. Violations can also be tracked on procedure state space level and hence offer more precise debugging instances. In order to avoid repetitive model checking of model checking instances, the algorithm applies model checking contracts for procedure state spaces in order to reuse model checking results that have been computed beforehand. Furthermore, the on-the-fly state space construction allows for early termination of the model checking procedure such that time and memory can be saved as not the complete state space needs to be generated. \\
	
	However, in case of model checking a procedure state space for multiple distinct LTL formulae, the procedure state space needs to be computed afresh as the on-the-fly approach does not necessarily compute complete state spaces that cannot be reused. This might cause an overhead of state space generations.\\
	
	Thus, the on-the-fly approach is especially suitable for cases in which erroneous behavior is expected within method executions in order to quickly find a counterexample, whereas positive validation of a property might cause an overhead of computations. \\
	
	Chapter~\ref{chp:benchmarks} presents benchmarks on the on-the-fly hierarchical model checking algorithm described in this chapter.
		
	
	%TODO example from introduction
	
	\chapter{Hierarchical Model Checking with Recursive State Machines}\label{chp:hmc}

	\section{Algorithm}
	
	\section{Implementation}
	%TODO add UML diagram / architecture?
	
	\section{Evaluation}
	
	
	\chapter{Benchmarks}\label{chp:benchmarks}	
	\section{Experimental Setup}
	Describe Technical details here
	\section{Instances}
	Describe code examples and properties here
	\section{Result}
	Table of values
	
	\chapter{Conclusion}
	\section{Discussion}	
	\section{Outlook}
	
		- hierarchical failure trace and counter example generation, spuriosity
	- hybrid method between on-the-fly and RSM
	
	\bibliographystyle{gerplain}
	\bibliography{lit}{}
	
\end{document}